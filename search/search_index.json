{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>An open source agent orchestration framework built on top of the latest OpenAI Assistants API.</p> <p> </p>"},{"location":"#what-is-agency-swarm","title":"What is Agency Swarm?","text":"<p>Agency Swarm started as a desire and effort of Arsenii Shatokhin (aka VRSEN) to fully automate his AI Agency with AI. By building this framework, we aim to simplify the agent creation process and enable anyoone to create collaborative swarm of agents (Agencies), each with distinct roles and capabilities. By thinking about automation in terms of real world entities, such as agencies and specialized agent roles, we make it a lot more intuitive for both the agents and the users. </p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Customizable Agent Roles: Define roles like CEO, virtual assistant, developer, etc., and customize their functionalities with Assistants API.</li> <li>Full Control Over Prompts: Avoid conflicts and restrictions of pre-defined prompts, allowing full customization.</li> <li>Tool Creation: Tools within Agency Swarm are created using Instructor, which provides a convenient interface and automatic type validation. </li> <li>Efficient Communication: Agents communicate through a specially designed \"send message\" tool based on their own descriptions.</li> <li>State Management: Agency Swarm efficiently manages the state of your assistants on OpenAI, maintaining it in a special <code>settings.json</code> file.</li> <li>Deployable in Production: Agency Swarm is designed to be reliable and easily deployable in production environments.</li> </ul>"},{"location":"#agency-swarm-vs-other-frameworks","title":"Agency Swarm vs Other Frameworks","text":"<p>Unlike other frameworks, Agency Swarm:</p> <ol> <li>Does not write prompts for you.</li> <li>Prevents hallucinations with automatic type checking and error correction with instructor</li> <li>Allows you to easily define communication flows.</li> </ol>"},{"location":"#autogen-vs-agency-swarm","title":"AutoGen vs Agency Swarm","text":"<p>In AutoGen, the next speaker is determined with an extra call to the model that emulates \"role play\" between the agents. [1] Not only this is very inefficient, but it also makes the system less controllable and less customizable, because you cannot control which agent can communicate with which other agent. In Agency Swarm, on the other hand, the communication is handled through the special <code>SendMessage</code> tool. [2] Your agents will determine who to communicate with based on their own descriptions. The caller agent will the receive the response as the function output, which makes it a lot more natural for your agents to understand the communication flow.</p>"},{"location":"#crewai-vs-agency-swarm","title":"CrewAI vs Agency Swarm","text":"<p>CrewAI introduces a concept of \"process\" [3] into agent communication, which provides some control over the communication flow. However, the biggest problem with CrewAI is that it is built on top of Langchain, which was created long before any function-calling models were released. This means that there is no type checking or error correction, so any action that your agent takes (which is the most important part of the system) could cause the whole system to go down if the model hallucinates. The sole advantage of CrewAI is its compatibility with open-source models.</p>"},{"location":"#need-help","title":"Need help?","text":"<p>If you need quick help with Agency Swarm, feel free to ask in the Discord server.</p> <p>If you need help creating custom agent swarms for your business, check out our Agents-as-a-Service subscription, or schedule a consultation with me at https://calendly.com/vrsen/ai-project-consultation</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the MIT license.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#agency_swarm.agents.agent.Agent","title":"<code>Agent</code>","text":"Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>class Agent():\n    @property\n    def assistant(self):\n        if self._assistant is None:\n            raise Exception(\"Assistant is not initialized. Please run init_oai() first.\")\n        return self._assistant\n\n    @assistant.setter\n    def assistant(self, value):\n        self._assistant = value\n\n    @property\n    def functions(self):\n        return [tool for tool in self.tools if issubclass(tool, BaseTool)]\n\n    def response_validator(self, message: str) -&gt; str:\n        \"\"\"\n        Validates the response from the agent. If the response is invalid, it must raise an exception with instructions\n        for the caller agent on how to proceed.\n\n        Parameters:\n            message (str): The response from the agent.\n\n        Returns:\n            str: The validated response.\n        \"\"\"\n        return message\n\n    def __init__(\n            self,\n            id: str = None,\n            name: str = None,\n            description: str = None,\n            instructions: str = \"\",\n            tools: List[Union[Type[BaseTool], Type[FileSearch], Type[CodeInterpreter], type[Retrieval]]] = None,\n            tool_resources: ToolResources = None,\n            temperature: float = None,\n            top_p: float = None,\n            response_format: str | dict = \"auto\",\n            tools_folder: str = None,\n            files_folder: Union[List[str], str] = None,\n            schemas_folder: Union[List[str], str] = None,\n            api_headers: Dict[str, Dict[str, str]] = None,\n            api_params: Dict[str, Dict[str, str]] = None,\n            file_ids: List[str] = None,\n            metadata: Dict[str, str] = None,\n            model: str = \"gpt-4-turbo\",\n            validation_attempts: int = 1,\n            max_prompt_tokens: int = None,\n            max_completion_tokens: int = None,\n            truncation_strategy: dict = None,\n            examples: List[ExampleMessage] = None,\n    ):\n        \"\"\"\n        Initializes an Agent with specified attributes, tools, and OpenAI client.\n\n        Parameters:\n            id (str, optional): Loads the assistant from OpenAI assistant ID. Assistant will be created or loaded from settings if ID is not provided. Defaults to None.\n            name (str, optional): Name of the agent. Defaults to the class name if not provided.\n            description (str, optional): A brief description of the agent's purpose. Defaults to None.\n            instructions (str, optional): Path to a file containing specific instructions for the agent. Defaults to an empty string.\n            tools (List[Union[Type[BaseTool], Type[Retrieval], Type[CodeInterpreter]]], optional): A list of tools (as classes) that the agent can use. Defaults to an empty list.\n            tool_resources (ToolResources, optional): A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs. Defaults to None.\n            temperature (float, optional): The temperature parameter for the OpenAI API. Defaults to None.\n            top_p (float, optional): The top_p parameter for the OpenAI API. Defaults to None.\n            response_format (Dict, optional): The response format for the OpenAI API. Defaults to None.\n            tools_folder (str, optional): Path to a directory containing tools associated with the agent. Each tool must be defined in a separate file. File must be named as the class name of the tool. Defaults to None.\n            files_folder (Union[List[str], str], optional): Path or list of paths to directories containing files associated with the agent. Defaults to None.\n            schemas_folder (Union[List[str], str], optional): Path or list of paths to directories containing OpenAPI schemas associated with the agent. Defaults to None.\n            api_headers (Dict[str,Dict[str, str]], optional): Headers to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.\n            api_params (Dict[str, Dict[str, str]], optional): Extra params to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.\n            metadata (Dict[str, str], optional): Metadata associated with the agent. Defaults to an empty dictionary.\n            model (str, optional): The model identifier for the OpenAI API. Defaults to \"gpt-4-turbo-preview\".\n            validation_attempts (int, optional): Number of attempts to validate the response with response_validator function. Defaults to 1.\n            max_prompt_tokens (int, optional): Maximum number of tokens allowed in the prompt. Defaults to None.\n            max_completion_tokens (int, optional): Maximum number of tokens allowed in the completion. Defaults to None.\n            truncation_strategy (TruncationStrategy, optional): Truncation strategy for the OpenAI API. Defaults to None.\n            examples (List[Dict], optional): A list of example messages for the agent. Defaults to None.\n\n        This constructor sets up the agent with its unique properties, initializes the OpenAI client, reads instructions if provided, and uploads any associated files.\n        \"\"\"\n        # public attributes\n        self.id = id\n        self.name = name if name else self.__class__.__name__\n        self.description = description\n        self.instructions = instructions\n        self.tools = tools[:] if tools is not None else []\n        self.tools = [tool for tool in self.tools if tool.__name__ != \"ExampleTool\"]\n        self.tool_resources = tool_resources\n        self.temperature = temperature\n        self.top_p = top_p\n        self.response_format = response_format\n        self.tools_folder = tools_folder\n        self.files_folder = files_folder if files_folder else []\n        self.schemas_folder = schemas_folder if schemas_folder else []\n        self.api_headers = api_headers if api_headers else {}\n        self.api_params = api_params if api_params else {}\n        self.metadata = metadata if metadata else {}\n        self.model = model\n        self.validation_attempts = validation_attempts\n        self.max_prompt_tokens = max_prompt_tokens\n        self.max_completion_tokens = max_completion_tokens\n        self.truncation_strategy = truncation_strategy\n        self.examples = examples\n\n        self.settings_path = './settings.json'\n\n        # private attributes\n        self._assistant: Any = None\n        self._shared_instructions = None\n\n        # init methods\n        self.client = get_openai_client()\n        self._read_instructions()\n\n        # upload files\n        self._upload_files()\n        if file_ids:\n            print(\"Warning: 'file_ids' parameter is deprecated. Please use 'tool_resources' parameter instead.\")\n            self.add_file_ids(file_ids, \"file_search\")\n\n        self._parse_schemas()\n        self._parse_tools_folder()\n\n    # --- OpenAI Assistant Methods ---\n\n    def init_oai(self):\n        \"\"\"\n        Initializes the OpenAI assistant for the agent.\n\n        This method handles the initialization and potential updates of the agent's OpenAI assistant. It loads the assistant based on a saved ID, updates the assistant if necessary, or creates a new assistant if it doesn't exist. After initialization or update, it saves the assistant's settings.\n\n        Output:\n            self: Returns the agent instance for chaining methods or further processing.\n        \"\"\"\n\n        # check if settings.json exists\n        path = self.get_settings_path()\n\n        # load assistant from id\n        if self.id:\n            self.assistant = self.client.beta.assistants.retrieve(self.id)\n            self.instructions = self.assistant.instructions\n            self.name = self.assistant.name\n            self.description = self.assistant.description\n            self.temperature = self.assistant.temperature\n            self.top_p = self.assistant.top_p\n            self.response_format = self.assistant.response_format\n            if not isinstance(self.response_format, str):\n                self.response_format = self.response_format.model_dump()\n            self.tool_resources = self.assistant.tool_resources.model_dump()\n            self.metadata = self.assistant.metadata\n            self.model = self.assistant.model\n            self.tool_resources = self.assistant.tool_resources.model_dump()\n            # update assistant if parameters are different\n            if not self._check_parameters(self.assistant.model_dump()):\n                self._update_assistant()\n            return self\n\n        # load assistant from settings\n        if os.path.exists(path):\n            with open(path, 'r') as f:\n                settings = json.load(f)\n                # iterate settings and find the assistant with the same name\n                for assistant_settings in settings:\n                    if assistant_settings['name'] == self.name:\n                        try:\n                            self.assistant = self.client.beta.assistants.retrieve(assistant_settings['id'])\n                            self.id = assistant_settings['id']\n                            if self.assistant.tool_resources:\n                                self.tool_resources = self.assistant.tool_resources.model_dump()\n                            # update assistant if parameters are different\n                            if not self._check_parameters(self.assistant.model_dump()):\n                                print(\"Updating assistant... \" + self.name)\n                                self._update_assistant()\n                            self._update_settings()\n                            return self\n                        except NotFoundError:\n                            continue\n\n        # create assistant if settings.json does not exist or assistant with the same name does not exist\n        self.assistant = self.client.beta.assistants.create(\n            model=self.model,\n            name=self.name,\n            description=self.description,\n            instructions=self.instructions,\n            tools=self.get_oai_tools(),\n            tool_resources=self.tool_resources,\n            metadata=self.metadata,\n            temperature=self.temperature,\n            top_p=self.top_p,\n            response_format=self.response_format,\n        )\n\n        if self.assistant.tool_resources:\n            self.tool_resources = self.assistant.tool_resources.model_dump()\n\n        self.id = self.assistant.id\n\n        self._save_settings()\n\n        return self\n\n    def _update_assistant(self):\n        \"\"\"\n        Updates the existing assistant's parameters on the OpenAI server.\n\n        This method updates the assistant's details such as name, description, instructions, tools, file IDs, metadata, and the model. It only updates parameters that have non-empty values. After updating the assistant, it also updates the local settings file to reflect these changes.\n\n        No input parameters are directly passed to this method as it uses the agent's instance attributes.\n\n        No output parameters are returned, but the method updates the assistant's details on the OpenAI server and locally updates the settings file.\n        \"\"\"\n\n        params = {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"instructions\": self.instructions,\n            \"tools\": self.get_oai_tools(),\n            \"tool_resources\": self.tool_resources,\n            \"temperature\": self.temperature,\n            \"top_p\": self.top_p,\n            \"response_format\": self.response_format,\n            \"metadata\": self.metadata,\n            \"model\": self.model\n        }\n        params = {k: v for k, v in params.items() if v}\n        self.assistant = self.client.beta.assistants.update(\n            self.id,\n            **params,\n        )\n        self._update_settings()\n\n    def _upload_files(self):\n        def add_id_to_file(f_path, id):\n            \"\"\"Add file id to file name\"\"\"\n            if os.path.isfile(f_path):\n                file_name, file_ext = os.path.splitext(f_path)\n                f_path_new = file_name + \"_\" + id + file_ext\n                os.rename(f_path, f_path_new)\n                return f_path_new\n\n        def get_id_from_file(f_path):\n            \"\"\"Get file id from file name\"\"\"\n            if os.path.isfile(f_path):\n                file_name, file_ext = os.path.splitext(f_path)\n                file_name = os.path.basename(file_name)\n                file_name = file_name.split(\"_\")\n                if len(file_name) &gt; 1:\n                    return file_name[-1] if \"file-\" in file_name[-1] else None\n                else:\n                    return None\n\n        files_folders = self.files_folder if isinstance(self.files_folder, list) else [self.files_folder]\n\n        file_search_ids = []\n        code_interpreter_ids = []\n\n        for files_folder in files_folders:\n            if isinstance(files_folder, str):\n                f_path = files_folder\n\n                if not os.path.isdir(f_path):\n                    f_path = os.path.join(self.get_class_folder_path(), files_folder)\n                    f_path = os.path.normpath(f_path)\n\n                if os.path.isdir(f_path):\n                    f_paths = os.listdir(f_path)\n\n                    f_paths = [f for f in f_paths if not f.startswith(\".\")]\n\n                    f_paths = [os.path.join(f_path, f) for f in f_paths]\n\n                    code_interpreter_file_extensions = [\n                        \".json\",  # JSON\n                        \".csv\",  # CSV\n                        \".xml\",  # XML\n                        \".jpeg\",  # JPEG\n                        \".jpg\",  # JPEG\n                        \".gif\",  # GIF\n                        \".png\",  # PNG\n                        \".zip\"  # ZIP\n                    ]\n\n                    for f_path in f_paths:\n                        file_ext = os.path.splitext(f_path)[1]\n\n                        f_path = f_path.strip()\n                        file_id = get_id_from_file(f_path)\n                        if file_id:\n                            print(\"File already uploaded. Skipping... \" + os.path.basename(f_path))\n                        else:\n                            print(\"Uploading new file... \" + os.path.basename(f_path))\n                            with open(f_path, 'rb') as f:\n                                file_id = self.client.with_options(\n                                    timeout=80 * 1000,\n                                ).files.create(file=f, purpose=\"assistants\").id\n                                f.close()\n                            add_id_to_file(f_path, file_id)\n\n                        if file_ext in code_interpreter_file_extensions:\n                            code_interpreter_ids.append(file_id)\n                        else:\n                            file_search_ids.append(file_id)\n                else:\n                    print(f\"Files folder '{f_path}' is not a directory. Skipping...\", )\n            else:\n                print(\"Files folder path must be a string or list of strings. Skipping... \", files_folder)\n\n        if FileSearch not in self.tools and file_search_ids:\n            print(\"Detected files without FileSearch. Adding FileSearch tool...\")\n            self.add_tool(FileSearch)\n        if CodeInterpreter not in self.tools and code_interpreter_ids:\n            print(\"Detected files without FileSearch. Adding FileSearch tool...\")\n            self.add_tool(CodeInterpreter)\n\n        self.add_file_ids(file_search_ids, \"file_search\")\n        self.add_file_ids(code_interpreter_ids, \"code_interpreter\")\n\n    # --- Tool Methods ---\n\n    # TODO: fix 2 methods below\n    def add_tool(self, tool):\n        if not isinstance(tool, type):\n            raise Exception(\"Tool must not be initialized.\")\n        if issubclass(tool, FileSearch):\n            # check that tools name is not already in tools\n            for t in self.tools:\n                if issubclass(t, FileSearch):\n                    return\n            self.tools.append(tool)\n        elif issubclass(tool, CodeInterpreter):\n            for t in self.tools:\n                if issubclass(t, CodeInterpreter):\n                    return\n            self.tools.append(tool)\n        elif issubclass(tool, Retrieval):\n            for t in self.tools:\n                if issubclass(t, Retrieval):\n                    return\n            self.tools.append(tool)\n        elif issubclass(tool, BaseTool):\n            if tool.__name__ == \"ExampleTool\":\n                print(\"Skipping importing ExampleTool...\")\n                return\n            for t in self.tools:\n                if t.__name__ == tool.__name__:\n                    self.tools.remove(t)\n            self.tools.append(tool)\n        else:\n            raise Exception(\"Invalid tool type.\")\n\n    def get_oai_tools(self):\n        tools = []\n        for tool in self.tools:\n            if not isinstance(tool, type):\n                print(tool)\n                raise Exception(\"Tool must not be initialized.\")\n\n            if issubclass(tool, FileSearch):\n                tools.append(tool().model_dump())\n            elif issubclass(tool, CodeInterpreter):\n                tools.append(tool().model_dump())\n            elif issubclass(tool, Retrieval):\n                tools.append(tool().model_dump())\n            elif issubclass(tool, BaseTool):\n                tools.append({\n                    \"type\": \"function\",\n                    \"function\": tool.openai_schema\n                })\n            else:\n                raise Exception(\"Invalid tool type.\")\n        return tools\n\n    def _parse_schemas(self):\n        schemas_folders = self.schemas_folder if isinstance(self.schemas_folder, list) else [self.schemas_folder]\n\n        for schemas_folder in schemas_folders:\n            if isinstance(schemas_folder, str):\n                f_path = schemas_folder\n\n                if not os.path.isdir(f_path):\n                    f_path = os.path.join(self.get_class_folder_path(), schemas_folder)\n                    f_path = os.path.normpath(f_path)\n\n                if os.path.isdir(f_path):\n                    f_paths = os.listdir(f_path)\n\n                    f_paths = [f for f in f_paths if not f.startswith(\".\")]\n\n                    f_paths = [os.path.join(f_path, f) for f in f_paths]\n\n                    for f_path in f_paths:\n                        with open(f_path, 'r') as f:\n                            openapi_spec = f.read()\n                            f.close()\n                        try:\n                            validate_openapi_spec(openapi_spec)\n                        except Exception as e:\n                            print(\"Invalid OpenAPI schema: \" + os.path.basename(f_path))\n                            raise e\n                        try:\n                            headers = None\n                            params = None\n                            if os.path.basename(f_path) in self.api_headers:\n                                headers = self.api_headers[os.path.basename(f_path)]\n                            if os.path.basename(f_path) in self.api_params:\n                                params = self.api_params[os.path.basename(f_path)]\n                            tools = ToolFactory.from_openapi_schema(openapi_spec, headers=headers, params=params)\n                        except Exception as e:\n                            print(\"Error parsing OpenAPI schema: \" + os.path.basename(f_path))\n                            raise e\n                        for tool in tools:\n                            self.add_tool(tool)\n                else:\n                    print(\"Schemas folder path is not a directory. Skipping... \", f_path)\n            else:\n                print(\"Schemas folder path must be a string or list of strings. Skipping... \", schemas_folder)\n\n    def _parse_tools_folder(self):\n        if not self.tools_folder:\n            return\n\n        if not os.path.isdir(self.tools_folder):\n            self.tools_folder = os.path.join(self.get_class_folder_path(), self.tools_folder)\n            self.tools_folder = os.path.normpath(self.tools_folder)\n\n        if os.path.isdir(self.tools_folder):\n            f_paths = os.listdir(self.tools_folder)\n            f_paths = [f for f in f_paths if not f.startswith(\".\") and not f.startswith(\"__\")]\n            f_paths = [os.path.join(self.tools_folder, f) for f in f_paths]\n            for f_path in f_paths:\n                if not f_path.endswith(\".py\"):\n                    continue\n                if os.path.isfile(f_path):\n                    try:\n                        tool = ToolFactory.from_file(f_path)\n                        self.add_tool(tool)\n                    except Exception as e:\n                        print(f\"Error parsing tool file {os.path.basename(f_path)}: {e}. Skipping...\")\n                else:\n                    print(\"Items in tools folder must be files. Skipping... \", f_path)\n        else:\n            print(\"Tools folder path is not a directory. Skipping... \", self.tools_folder)\n\n    def get_openapi_schema(self, url):\n        \"\"\"Get openapi schema that contains all tools from the agent as different api paths. Make sure to call this after agency has been initialized.\"\"\"\n        if self.assistant is None:\n            raise Exception(\n                \"Assistant is not initialized. Please initialize the agency first, before using this method\")\n\n        return ToolFactory.get_openapi_schema(self.tools, url)\n\n    # --- Settings Methods ---\n\n    def _check_parameters(self, assistant_settings):\n        \"\"\"\n        Checks if the agent's parameters match with the given assistant settings.\n\n        Parameters:\n            assistant_settings (dict): A dictionary containing the settings of an assistant.\n\n        Returns:\n            bool: True if all the agent's parameters match the assistant settings, False otherwise.\n\n        This method compares the current agent's parameters such as name, description, instructions, tools, file IDs, metadata, and model with the given assistant settings. It uses DeepDiff to compare complex structures like tools and metadata. If any parameter does not match, it returns False; otherwise, it returns True.\n        \"\"\"\n        if self.name != assistant_settings['name']:\n            return False\n\n        if self.description != assistant_settings['description']:\n            return False\n\n        if self.instructions != assistant_settings['instructions']:\n            return False\n\n        tools_diff = DeepDiff(self.get_oai_tools(), assistant_settings['tools'], ignore_order=True)\n        if tools_diff != {}:\n            return False\n\n        if self.temperature != assistant_settings['temperature']:\n            return False\n\n        if self.top_p != assistant_settings['top_p']:\n            return False\n\n        tool_resources_settings = copy.deepcopy(self.tool_resources)\n        if tool_resources_settings and tool_resources_settings.get('file_search'):\n            tool_resources_settings['file_search'].pop('vector_stores', None)\n        tool_resources_diff = DeepDiff(tool_resources_settings, assistant_settings['tool_resources'], ignore_order=True)\n        if tool_resources_diff != {}:\n            return False\n\n        metadata_diff = DeepDiff(self.metadata, assistant_settings['metadata'], ignore_order=True)\n        if metadata_diff != {}:\n            return False\n\n        if self.model != assistant_settings['model']:\n            return False\n\n        response_format_diff = DeepDiff(self.response_format, assistant_settings['response_format'], ignore_order=True)\n        if response_format_diff != {}:\n            return False\n\n        return True\n\n    def _save_settings(self):\n        path = self.get_settings_path()\n        # check if settings.json exists\n        if not os.path.isfile(path):\n            with open(path, 'w') as f:\n                json.dump([self.assistant.model_dump()], f, indent=4)\n        else:\n            settings = []\n            with open(path, 'r') as f:\n                settings = json.load(f)\n                settings.append(self.assistant.model_dump())\n            with open(path, 'w') as f:\n                json.dump(settings, f, indent=4)\n\n    def _update_settings(self):\n        path = self.get_settings_path()\n        # check if settings.json exists\n        if os.path.isfile(path):\n            settings = []\n            with open(path, 'r') as f:\n                settings = json.load(f)\n                for i, assistant_settings in enumerate(settings):\n                    if assistant_settings['id'] == self.id:\n                        settings[i] = self.assistant.model_dump()\n                        break\n            with open(path, 'w') as f:\n                json.dump(settings, f, indent=4)\n\n    # --- Helper Methods ---\n\n    def add_file_ids(self, file_ids: List[str], tool_resource: Literal[\"code_interpreter\", \"file_search\"]):\n        if not file_ids:\n            return\n\n        if self.tool_resources is None:\n            self.tool_resources = {}\n\n        if tool_resource == \"code_interpreter\":\n            if CodeInterpreter not in self.tools:\n                raise Exception(\"CodeInterpreter tool not found in tools.\")\n\n            if tool_resource not in self.tool_resources or self.tool_resources[\n                tool_resource] is None:\n                self.tool_resources[tool_resource] = {\n                    \"file_ids\": file_ids\n                }\n\n            self.tool_resources[tool_resource]['file_ids'] = file_ids\n        elif tool_resource == \"file_search\":\n            if FileSearch not in self.tools:\n                raise Exception(\"FileSearch tool not found in tools.\")\n\n            if tool_resource not in self.tool_resources or self.tool_resources[\n                tool_resource] is None:\n                self.tool_resources[tool_resource] = {\n                    \"vector_stores\": [{\n                        \"file_ids\": file_ids\n                    }]\n                }\n            elif not self.tool_resources[tool_resource].get('vector_store_ids'):\n                self.tool_resources[tool_resource]['vector_stores'] = [{\n                    \"file_ids\": file_ids\n                }]\n            else:\n                vector_store_id = self.tool_resources[tool_resource]['vector_store_ids'][0]\n                self.client.beta.vector_stores.file_batches.create(\n                    vector_store_id=vector_store_id,\n                    file_ids=file_ids\n                )\n        else:\n            raise Exception(\"Invalid tool resource.\")\n\n    def get_settings_path(self):\n        return self.settings_path\n\n    def _read_instructions(self):\n        class_instructions_path = os.path.normpath(os.path.join(self.get_class_folder_path(), self.instructions))\n        if os.path.isfile(class_instructions_path):\n            with open(class_instructions_path, 'r') as f:\n                self.instructions = f.read()\n        elif os.path.isfile(self.instructions):\n            with open(self.instructions, 'r') as f:\n                self.instructions = f.read()\n        elif \"./instructions.md\" in self.instructions or \"./instructions.txt\" in self.instructions:\n            raise Exception(\"Instructions file not found.\")\n\n    def get_class_folder_path(self):\n        try:\n            # First, try to use the __file__ attribute of the module\n            return os.path.abspath(os.path.dirname(self.__module__.__file__))\n        except (TypeError, OSError, AttributeError) as e:\n            # If that fails, fall back to inspect\n            try:\n                class_file = inspect.getfile(self.__class__)\n            except (TypeError, OSError, AttributeError) as e:\n                return \"./\"\n            return os.path.abspath(os.path.realpath(os.path.dirname(class_file)))\n\n    def add_shared_instructions(self, instructions: str):\n        if not instructions:\n            return\n\n        if self._shared_instructions is None:\n            self._shared_instructions = instructions\n        else:\n            self.instructions = self.instructions.replace(self._shared_instructions, \"\")\n            self.instructions = self.instructions.strip().strip(\"\\n\")\n            self._shared_instructions = instructions\n\n        self.instructions = self._shared_instructions + \"\\n\\n\" + self.instructions\n\n    # --- Cleanup Methods ---\n    def delete(self):\n        \"\"\"Deletes assistant, all vector stores, and all files associated with the agent.\"\"\"\n        self._delete_assistant()\n        self._delete_files()\n        self._delete_settings()\n\n    def _delete_files(self):\n        if not self.tool_resources:\n            return\n\n        file_ids = []\n        if self.tool_resources.get('code_interpreter'):\n            file_ids = self.tool_resources['code_interpreter'].get('file_ids', [])\n\n        if self.tool_resources.get('file_search'):\n            file_search_vector_store_ids = self.tool_resources['file_search'].get('vector_store_ids', [])\n            for vector_store_id in file_search_vector_store_ids:\n                files = self.client.beta.vector_stores.files.list(vector_store_id=vector_store_id, limit=100)\n                for file in files:\n                    file_ids.append(file.id)\n\n                self.client.beta.vector_stores.delete(vector_store_id)\n\n        for file_id in file_ids:\n            self.client.files.delete(file_id)\n\n    def _delete_assistant(self):\n        self.client.beta.assistants.delete(self.id)\n        self._delete_settings()\n\n    def _delete_settings(self):\n        path = self.get_settings_path()\n        # check if settings.json exists\n        if os.path.isfile(path):\n            settings = []\n            with open(path, 'r') as f:\n                settings = json.load(f)\n                for i, assistant_settings in enumerate(settings):\n                    if assistant_settings['id'] == self.id:\n                        settings.pop(i)\n                        break\n            with open(path, 'w') as f:\n                json.dump(settings, f, indent=4)\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent.__init__","title":"<code>__init__(id=None, name=None, description=None, instructions='', tools=None, tool_resources=None, temperature=None, top_p=None, response_format='auto', tools_folder=None, files_folder=None, schemas_folder=None, api_headers=None, api_params=None, file_ids=None, metadata=None, model='gpt-4-turbo', validation_attempts=1, max_prompt_tokens=None, max_completion_tokens=None, truncation_strategy=None, examples=None)</code>","text":"<p>Initializes an Agent with specified attributes, tools, and OpenAI client.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Loads the assistant from OpenAI assistant ID. Assistant will be created or loaded from settings if ID is not provided. Defaults to None.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the agent. Defaults to the class name if not provided.</p> <code>None</code> <code>description</code> <code>str</code> <p>A brief description of the agent's purpose. Defaults to None.</p> <code>None</code> <code>instructions</code> <code>str</code> <p>Path to a file containing specific instructions for the agent. Defaults to an empty string.</p> <code>''</code> <code>tools</code> <code>List[Union[Type[BaseTool], Type[Retrieval], Type[CodeInterpreter]]]</code> <p>A list of tools (as classes) that the agent can use. Defaults to an empty list.</p> <code>None</code> <code>tool_resources</code> <code>ToolResources</code> <p>A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs. Defaults to None.</p> <code>None</code> <code>temperature</code> <code>float</code> <p>The temperature parameter for the OpenAI API. Defaults to None.</p> <code>None</code> <code>top_p</code> <code>float</code> <p>The top_p parameter for the OpenAI API. Defaults to None.</p> <code>None</code> <code>response_format</code> <code>Dict</code> <p>The response format for the OpenAI API. Defaults to None.</p> <code>'auto'</code> <code>tools_folder</code> <code>str</code> <p>Path to a directory containing tools associated with the agent. Each tool must be defined in a separate file. File must be named as the class name of the tool. Defaults to None.</p> <code>None</code> <code>files_folder</code> <code>Union[List[str], str]</code> <p>Path or list of paths to directories containing files associated with the agent. Defaults to None.</p> <code>None</code> <code>schemas_folder</code> <code>Union[List[str], str]</code> <p>Path or list of paths to directories containing OpenAPI schemas associated with the agent. Defaults to None.</p> <code>None</code> <code>api_headers</code> <code>Dict[str, Dict[str, str]]</code> <p>Headers to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.</p> <code>None</code> <code>api_params</code> <code>Dict[str, Dict[str, str]]</code> <p>Extra params to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.</p> <code>None</code> <code>metadata</code> <code>Dict[str, str]</code> <p>Metadata associated with the agent. Defaults to an empty dictionary.</p> <code>None</code> <code>model</code> <code>str</code> <p>The model identifier for the OpenAI API. Defaults to \"gpt-4-turbo-preview\".</p> <code>'gpt-4-turbo'</code> <code>validation_attempts</code> <code>int</code> <p>Number of attempts to validate the response with response_validator function. Defaults to 1.</p> <code>1</code> <code>max_prompt_tokens</code> <code>int</code> <p>Maximum number of tokens allowed in the prompt. Defaults to None.</p> <code>None</code> <code>max_completion_tokens</code> <code>int</code> <p>Maximum number of tokens allowed in the completion. Defaults to None.</p> <code>None</code> <code>truncation_strategy</code> <code>TruncationStrategy</code> <p>Truncation strategy for the OpenAI API. Defaults to None.</p> <code>None</code> <code>examples</code> <code>List[Dict]</code> <p>A list of example messages for the agent. Defaults to None.</p> <code>None</code> <p>This constructor sets up the agent with its unique properties, initializes the OpenAI client, reads instructions if provided, and uploads any associated files.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def __init__(\n        self,\n        id: str = None,\n        name: str = None,\n        description: str = None,\n        instructions: str = \"\",\n        tools: List[Union[Type[BaseTool], Type[FileSearch], Type[CodeInterpreter], type[Retrieval]]] = None,\n        tool_resources: ToolResources = None,\n        temperature: float = None,\n        top_p: float = None,\n        response_format: str | dict = \"auto\",\n        tools_folder: str = None,\n        files_folder: Union[List[str], str] = None,\n        schemas_folder: Union[List[str], str] = None,\n        api_headers: Dict[str, Dict[str, str]] = None,\n        api_params: Dict[str, Dict[str, str]] = None,\n        file_ids: List[str] = None,\n        metadata: Dict[str, str] = None,\n        model: str = \"gpt-4-turbo\",\n        validation_attempts: int = 1,\n        max_prompt_tokens: int = None,\n        max_completion_tokens: int = None,\n        truncation_strategy: dict = None,\n        examples: List[ExampleMessage] = None,\n):\n    \"\"\"\n    Initializes an Agent with specified attributes, tools, and OpenAI client.\n\n    Parameters:\n        id (str, optional): Loads the assistant from OpenAI assistant ID. Assistant will be created or loaded from settings if ID is not provided. Defaults to None.\n        name (str, optional): Name of the agent. Defaults to the class name if not provided.\n        description (str, optional): A brief description of the agent's purpose. Defaults to None.\n        instructions (str, optional): Path to a file containing specific instructions for the agent. Defaults to an empty string.\n        tools (List[Union[Type[BaseTool], Type[Retrieval], Type[CodeInterpreter]]], optional): A list of tools (as classes) that the agent can use. Defaults to an empty list.\n        tool_resources (ToolResources, optional): A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs. Defaults to None.\n        temperature (float, optional): The temperature parameter for the OpenAI API. Defaults to None.\n        top_p (float, optional): The top_p parameter for the OpenAI API. Defaults to None.\n        response_format (Dict, optional): The response format for the OpenAI API. Defaults to None.\n        tools_folder (str, optional): Path to a directory containing tools associated with the agent. Each tool must be defined in a separate file. File must be named as the class name of the tool. Defaults to None.\n        files_folder (Union[List[str], str], optional): Path or list of paths to directories containing files associated with the agent. Defaults to None.\n        schemas_folder (Union[List[str], str], optional): Path or list of paths to directories containing OpenAPI schemas associated with the agent. Defaults to None.\n        api_headers (Dict[str,Dict[str, str]], optional): Headers to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.\n        api_params (Dict[str, Dict[str, str]], optional): Extra params to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.\n        metadata (Dict[str, str], optional): Metadata associated with the agent. Defaults to an empty dictionary.\n        model (str, optional): The model identifier for the OpenAI API. Defaults to \"gpt-4-turbo-preview\".\n        validation_attempts (int, optional): Number of attempts to validate the response with response_validator function. Defaults to 1.\n        max_prompt_tokens (int, optional): Maximum number of tokens allowed in the prompt. Defaults to None.\n        max_completion_tokens (int, optional): Maximum number of tokens allowed in the completion. Defaults to None.\n        truncation_strategy (TruncationStrategy, optional): Truncation strategy for the OpenAI API. Defaults to None.\n        examples (List[Dict], optional): A list of example messages for the agent. Defaults to None.\n\n    This constructor sets up the agent with its unique properties, initializes the OpenAI client, reads instructions if provided, and uploads any associated files.\n    \"\"\"\n    # public attributes\n    self.id = id\n    self.name = name if name else self.__class__.__name__\n    self.description = description\n    self.instructions = instructions\n    self.tools = tools[:] if tools is not None else []\n    self.tools = [tool for tool in self.tools if tool.__name__ != \"ExampleTool\"]\n    self.tool_resources = tool_resources\n    self.temperature = temperature\n    self.top_p = top_p\n    self.response_format = response_format\n    self.tools_folder = tools_folder\n    self.files_folder = files_folder if files_folder else []\n    self.schemas_folder = schemas_folder if schemas_folder else []\n    self.api_headers = api_headers if api_headers else {}\n    self.api_params = api_params if api_params else {}\n    self.metadata = metadata if metadata else {}\n    self.model = model\n    self.validation_attempts = validation_attempts\n    self.max_prompt_tokens = max_prompt_tokens\n    self.max_completion_tokens = max_completion_tokens\n    self.truncation_strategy = truncation_strategy\n    self.examples = examples\n\n    self.settings_path = './settings.json'\n\n    # private attributes\n    self._assistant: Any = None\n    self._shared_instructions = None\n\n    # init methods\n    self.client = get_openai_client()\n    self._read_instructions()\n\n    # upload files\n    self._upload_files()\n    if file_ids:\n        print(\"Warning: 'file_ids' parameter is deprecated. Please use 'tool_resources' parameter instead.\")\n        self.add_file_ids(file_ids, \"file_search\")\n\n    self._parse_schemas()\n    self._parse_tools_folder()\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent.delete","title":"<code>delete()</code>","text":"<p>Deletes assistant, all vector stores, and all files associated with the agent.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def delete(self):\n    \"\"\"Deletes assistant, all vector stores, and all files associated with the agent.\"\"\"\n    self._delete_assistant()\n    self._delete_files()\n    self._delete_settings()\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent.get_openapi_schema","title":"<code>get_openapi_schema(url)</code>","text":"<p>Get openapi schema that contains all tools from the agent as different api paths. Make sure to call this after agency has been initialized.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def get_openapi_schema(self, url):\n    \"\"\"Get openapi schema that contains all tools from the agent as different api paths. Make sure to call this after agency has been initialized.\"\"\"\n    if self.assistant is None:\n        raise Exception(\n            \"Assistant is not initialized. Please initialize the agency first, before using this method\")\n\n    return ToolFactory.get_openapi_schema(self.tools, url)\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent.init_oai","title":"<code>init_oai()</code>","text":"<p>Initializes the OpenAI assistant for the agent.</p> <p>This method handles the initialization and potential updates of the agent's OpenAI assistant. It loads the assistant based on a saved ID, updates the assistant if necessary, or creates a new assistant if it doesn't exist. After initialization or update, it saves the assistant's settings.</p> Output <p>self: Returns the agent instance for chaining methods or further processing.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def init_oai(self):\n    \"\"\"\n    Initializes the OpenAI assistant for the agent.\n\n    This method handles the initialization and potential updates of the agent's OpenAI assistant. It loads the assistant based on a saved ID, updates the assistant if necessary, or creates a new assistant if it doesn't exist. After initialization or update, it saves the assistant's settings.\n\n    Output:\n        self: Returns the agent instance for chaining methods or further processing.\n    \"\"\"\n\n    # check if settings.json exists\n    path = self.get_settings_path()\n\n    # load assistant from id\n    if self.id:\n        self.assistant = self.client.beta.assistants.retrieve(self.id)\n        self.instructions = self.assistant.instructions\n        self.name = self.assistant.name\n        self.description = self.assistant.description\n        self.temperature = self.assistant.temperature\n        self.top_p = self.assistant.top_p\n        self.response_format = self.assistant.response_format\n        if not isinstance(self.response_format, str):\n            self.response_format = self.response_format.model_dump()\n        self.tool_resources = self.assistant.tool_resources.model_dump()\n        self.metadata = self.assistant.metadata\n        self.model = self.assistant.model\n        self.tool_resources = self.assistant.tool_resources.model_dump()\n        # update assistant if parameters are different\n        if not self._check_parameters(self.assistant.model_dump()):\n            self._update_assistant()\n        return self\n\n    # load assistant from settings\n    if os.path.exists(path):\n        with open(path, 'r') as f:\n            settings = json.load(f)\n            # iterate settings and find the assistant with the same name\n            for assistant_settings in settings:\n                if assistant_settings['name'] == self.name:\n                    try:\n                        self.assistant = self.client.beta.assistants.retrieve(assistant_settings['id'])\n                        self.id = assistant_settings['id']\n                        if self.assistant.tool_resources:\n                            self.tool_resources = self.assistant.tool_resources.model_dump()\n                        # update assistant if parameters are different\n                        if not self._check_parameters(self.assistant.model_dump()):\n                            print(\"Updating assistant... \" + self.name)\n                            self._update_assistant()\n                        self._update_settings()\n                        return self\n                    except NotFoundError:\n                        continue\n\n    # create assistant if settings.json does not exist or assistant with the same name does not exist\n    self.assistant = self.client.beta.assistants.create(\n        model=self.model,\n        name=self.name,\n        description=self.description,\n        instructions=self.instructions,\n        tools=self.get_oai_tools(),\n        tool_resources=self.tool_resources,\n        metadata=self.metadata,\n        temperature=self.temperature,\n        top_p=self.top_p,\n        response_format=self.response_format,\n    )\n\n    if self.assistant.tool_resources:\n        self.tool_resources = self.assistant.tool_resources.model_dump()\n\n    self.id = self.assistant.id\n\n    self._save_settings()\n\n    return self\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent.response_validator","title":"<code>response_validator(message)</code>","text":"<p>Validates the response from the agent. If the response is invalid, it must raise an exception with instructions for the caller agent on how to proceed.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The response from the agent.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The validated response.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def response_validator(self, message: str) -&gt; str:\n    \"\"\"\n    Validates the response from the agent. If the response is invalid, it must raise an exception with instructions\n    for the caller agent on how to proceed.\n\n    Parameters:\n        message (str): The response from the agent.\n\n    Returns:\n        str: The validated response.\n    \"\"\"\n    return message\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency","title":"<code>Agency</code>","text":"Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>class Agency:\n    ThreadType = Thread\n    send_message_tool_description = \"\"\"Use this tool to facilitate direct, synchronous communication between specialized agents within your agency. When you send a message using this tool, you receive a response exclusively from the designated recipient agent. To continue the dialogue, invoke this tool again with the desired recipient agent and your follow-up message. Remember, communication here is synchronous; the recipient agent won't perform any tasks post-response. You are responsible for relaying the recipient agent's responses back to the user, as the user does not have direct access to these replies. Keep engaging with the tool for continuous interaction until the task is fully resolved. Do not send more than 1 message at a time.\"\"\"\n    send_message_tool_description_async = \"\"\"Use this tool for asynchronous communication with other agents within your agency. Initiate tasks by messaging, and check status and responses later with the 'GetResponse' tool. Relay responses to the user, who instructs on status checks. Continue until task completion.\"\"\"\n\n    def __init__(self,\n                 agency_chart: List,\n                 shared_instructions: str = \"\",\n                 shared_files: Union[str, List[str]] = None,\n                 async_mode: Literal['threading'] = None,\n                 settings_path: str = \"./settings.json\",\n                 settings_callbacks: SettingsCallbacks = None,\n                 threads_callbacks: ThreadsCallbacks = None,\n                 temperature: float = 0.3,\n                 top_p: float = 1.0,\n                 max_prompt_tokens: int = None,\n                 max_completion_tokens: int = None,\n                 truncation_strategy: dict = None,\n                 ):\n        \"\"\"\n        Initializes the Agency object, setting up agents, threads, and core functionalities.\n\n        Parameters:\n            agency_chart: The structure defining the hierarchy and interaction of agents within the agency.\n            shared_instructions (str, optional): A path to a file containing shared instructions for all agents. Defaults to an empty string.\n            shared_files (Union[str, List[str]], optional): A path to a folder or a list of folders containing shared files for all agents. Defaults to None.\n            async_mode (str, optional): The mode for asynchronous message processing. Defaults to None.\n            settings_path (str, optional): The path to the settings file for the agency. Must be json. If file does not exist, it will be created. Defaults to None.\n            settings_callbacks (SettingsCallbacks, optional): A dictionary containing functions to load and save settings for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.\n            threads_callbacks (ThreadsCallbacks, optional): A dictionary containing functions to load and save threads for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.\n            temperature (float, optional): The temperature value to use for the agents. Agent specific values will override this. Defaults to 0.3.\n            top_p (float, optional): The top_p value to use for the agents. Agent specific values will override this. Defaults to None.\n            max_prompt_tokens (int, optional): The maximum number of tokens allowed in the prompt for each agent. Agent specific values will override this. Defaults to None.\n            max_completion_tokens (int, optional): The maximum number of tokens allowed in the completion for each agent. Agent specific values will override this. Defaults to None.\n            truncation_strategy (dict, optional): The truncation strategy to use for the completion for each agent. Agent specific values will override this. Defaults to None.\n\n        This constructor initializes various components of the Agency, including CEO, agents, threads, and user interactions. It parses the agency chart to set up the organizational structure and initializes the messaging tools, agents, and threads necessary for the operation of the agency. Additionally, it prepares a main thread for user interactions.\n        \"\"\"\n        self.async_mode = async_mode\n        if self.async_mode == \"threading\":\n            from agency_swarm.threads.thread_async import ThreadAsync\n            self.ThreadType = ThreadAsync\n\n        self.ceo = None\n        self.user = User()\n        self.agents = []\n        self.agents_and_threads = {}\n        self.main_recipients = []\n        self.main_thread = None\n        self.recipient_agents = None  # for autocomplete\n        self.shared_files = shared_files if shared_files else []\n        self.settings_path = settings_path\n        self.settings_callbacks = settings_callbacks\n        self.threads_callbacks = threads_callbacks\n        self.temperature = temperature\n        self.top_p = top_p\n        self.max_prompt_tokens = max_prompt_tokens\n        self.max_completion_tokens = max_completion_tokens\n        self.truncation_strategy = truncation_strategy\n\n        if os.path.isfile(os.path.join(self._get_class_folder_path(), shared_instructions)):\n            self._read_instructions(os.path.join(self._get_class_folder_path(), shared_instructions))\n        elif os.path.isfile(shared_instructions):\n            self._read_instructions(shared_instructions)\n        else:\n            self.shared_instructions = shared_instructions\n\n        self._parse_agency_chart(agency_chart)\n        self._create_special_tools()\n        self._init_agents()\n        self._init_threads()\n\n    def get_completion(self, message: str,\n                       message_files: List[str] = None,\n                       yield_messages: bool = False,\n                       recipient_agent: Agent = None,\n                       additional_instructions: str = None,\n                       attachments: List[dict] = None,\n                       tool_choice: dict = None,\n                       ):\n        \"\"\"\n        Retrieves the completion for a given message from the main thread.\n\n        Parameters:\n            message (str): The message for which completion is to be retrieved.\n            message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n            yield_messages (bool, optional): Flag to determine if intermediate messages should be yielded. Defaults to True.\n            recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n            additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n            attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n            tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n\n        Returns:\n            Generator or final response: Depending on the 'yield_messages' flag, this method returns either a generator yielding intermediate messages or the final response from the main thread.\n        \"\"\"\n        if yield_messages:\n            print(\"Warning: yield_messages parameter is deprecated. Use streaming instead.\")\n\n        return self.main_thread.get_completion(message=message,\n                                               message_files=message_files,\n                                               attachments=attachments,\n                                               recipient_agent=recipient_agent,\n                                               additional_instructions=additional_instructions,\n                                               tool_choice=tool_choice)\n\n    def get_completion_stream(self,\n                              message: str,\n                              event_handler: type(AgencyEventHandler),\n                              message_files: List[str] = None,\n                              recipient_agent: Agent = None,\n                              additional_instructions: str = None,\n                              attachments: List[dict] = None,\n                              tool_choice: dict = None\n                              ):\n        \"\"\"\n        Generates a stream of completions for a given message from the main thread.\n\n        Parameters:\n            message (str): The message for which completion is to be retrieved.\n            event_handler (type(AgencyEventHandler)): The event handler class to handle the completion stream. https://github.com/openai/openai-python/blob/main/helpers.md\n            message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n            recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n            additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n            attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n            tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n\n        Returns:\n            Final response: Final response from the main thread.\n        \"\"\"\n        if self.async_mode:\n            raise Exception(\"Streaming is not supported in async mode.\")\n\n        if not inspect.isclass(event_handler):\n            raise Exception(\"Event handler must not be an instance.\")\n\n        res = self.main_thread.get_completion_stream(message=message,\n                                                      message_files=message_files,\n                                                      event_handler=event_handler,\n                                                      attachments=attachments,\n                                                      recipient_agent=recipient_agent,\n                                                      additional_instructions=additional_instructions,\n                                                      tool_choice=tool_choice\n                                                      )\n\n        event_handler.on_all_streams_end()\n\n        return res\n\n    def demo_gradio(self, height=450, dark_mode=True, **kwargs):\n        \"\"\"\n        Launches a Gradio-based demo interface for the agency chatbot.\n\n        Parameters:\n            height (int, optional): The height of the chatbot widget in the Gradio interface. Default is 600.\n            dark_mode (bool, optional): Flag to determine if the interface should be displayed in dark mode. Default is True.\n            **kwargs: Additional keyword arguments to be passed to the Gradio interface.\n        This method sets up and runs a Gradio interface, allowing users to interact with the agency's chatbot. It includes a text input for the user's messages and a chatbot interface for displaying the conversation. The method handles user input and chatbot responses, updating the interface dynamically.\n        \"\"\"\n\n        try:\n            import gradio as gr\n        except ImportError:\n            raise Exception(\"Please install gradio: pip install gradio\")\n\n        js = \"\"\"function () {\n          gradioURL = window.location.href\n          if (!gradioURL.endsWith('?__theme={theme}')) {\n            window.location.replace(gradioURL + '?__theme={theme}');\n          }\n        }\"\"\"\n\n        if dark_mode:\n            js = js.replace(\"{theme}\", \"dark\")\n        else:\n            js = js.replace(\"{theme}\", \"light\")\n\n        message_file_ids = []\n        message_file_names = None\n        recipient_agents = [agent.name for agent in self.main_recipients]\n        recipient_agent = self.main_recipients[0]\n\n        with gr.Blocks(js=js) as demo:\n            chatbot_queue = queue.Queue()\n            chatbot = gr.Chatbot(height=height)\n            with gr.Row():\n                with gr.Column(scale=9):\n                    dropdown = gr.Dropdown(label=\"Recipient Agent\", choices=recipient_agents,\n                                           value=recipient_agent.name)\n                    msg = gr.Textbox(label=\"Your Message\", lines=4)\n                with gr.Column(scale=1):\n                    file_upload = gr.Files(label=\"Files\", type=\"filepath\")\n            button = gr.Button(value=\"Send\", variant=\"primary\")\n\n            def handle_dropdown_change(selected_option):\n                nonlocal recipient_agent\n                recipient_agent = self._get_agent_by_name(selected_option)\n\n            def handle_file_upload(file_list):\n                nonlocal message_file_ids\n                nonlocal message_file_names\n                message_file_ids = []\n                message_file_names = []\n                if file_list:\n                    try:\n                        for file_obj in file_list:\n                            with open(file_obj.name, 'rb') as f:\n                                # Upload the file to OpenAI\n                                file = self.main_thread.client.files.create(\n                                    file=f,\n                                    purpose=\"assistants\"\n                                )\n                            message_file_ids.append(file.id)\n                            message_file_names.append(file.filename)\n                            print(f\"Uploaded file ID: {file.id}\")\n                        return message_file_ids\n                    except Exception as e:\n                        print(f\"Error: {e}\")\n                        return str(e)\n\n                return \"No files uploaded\"\n\n            def user(user_message, history):\n                if history is None:\n                    history = []\n\n                original_user_message = user_message\n\n                # Append the user message with a placeholder for bot response\n                if recipient_agent:\n                    user_message = f\"\ud83d\udc64 User \ud83d\udde3\ufe0f @{recipient_agent.name}:\\n\" + user_message.strip()\n                else:\n                    user_message = f\"\ud83d\udc64 User:\" + user_message.strip()\n\n                nonlocal message_file_names\n                if message_file_names:\n                    user_message += \"\\n\\n\ud83d\udcce Files:\\n\" + \"\\n\".join(message_file_names)\n\n                return original_user_message, history + [[user_message, None]]\n\n            class GradioEventHandler(AgencyEventHandler):\n                message_output = None\n\n                @override\n                def on_message_created(self, message: Message) -&gt; None:\n                    if message.role == \"user\":\n                        self.message_output = MessageOutput(\"text\", self.agent_name, self.recipient_agent_name,\n                                                            message.content[0].text.value)\n\n                    else:\n                        self.message_output = MessageOutput(\"text\", self.recipient_agent_name, self.agent_name,\n                                                            \"\")\n\n                    chatbot_queue.put(\"[new_message]\")\n                    chatbot_queue.put(self.message_output.get_formatted_content())\n\n                @override\n                def on_text_delta(self, delta, snapshot):\n                    chatbot_queue.put(delta.value)\n\n                @override\n                def on_tool_call_created(self, tool_call):\n                    # TODO: add support for code interpreter and retirieval tools\n                    if tool_call.type == \"function\":\n                        chatbot_queue.put(\"[new_message]\")\n                        self.message_output = MessageOutput(\"function\", self.recipient_agent_name, self.agent_name,\n                                                            str(tool_call.function))\n                        chatbot_queue.put(self.message_output.get_formatted_header() + \"\\n\")\n\n                @override\n                def on_tool_call_done(self, snapshot):\n                    self.message_output = None\n\n                    # TODO: add support for code interpreter and retirieval tools\n                    if snapshot.type != \"function\":\n                        return\n\n                    chatbot_queue.put(str(snapshot.function))\n\n                    if snapshot.function.name == \"SendMessage\":\n                        try:\n                            args = eval(snapshot.function.arguments)\n                            recipient = args[\"recipient\"]\n                            self.message_output = MessageOutput(\"text\", self.recipient_agent_name, recipient,\n                                                                args[\"message\"])\n\n                            chatbot_queue.put(\"[new_message]\")\n                            chatbot_queue.put(self.message_output.get_formatted_content())\n                        except Exception as e:\n                            pass\n\n                    self.message_output = None\n\n                @override\n                def on_run_step_done(self, run_step: RunStep) -&gt; None:\n                    if run_step.type == \"tool_calls\":\n                        for tool_call in run_step.step_details.tool_calls:\n                            if tool_call.type != \"function\":\n                                continue\n\n                            if tool_call.function.name == \"SendMessage\":\n                                continue\n\n                            self.message_output = None\n                            chatbot_queue.put(\"[new_message]\")\n\n                            self.message_output = MessageOutput(\"function_output\", tool_call.function.name,\n                                                                self.recipient_agent_name,\n                                                                tool_call.function.output)\n\n                            chatbot_queue.put(self.message_output.get_formatted_header() + \"\\n\")\n                            chatbot_queue.put(tool_call.function.output)\n\n                @override\n                @classmethod\n                def on_all_streams_end(cls):\n                    self.message_output = None\n                    chatbot_queue.put(\"[end]\")\n\n            def bot(original_message, history):\n                nonlocal message_file_ids\n                nonlocal message_file_names\n                nonlocal recipient_agent\n                print(\"Message files: \", message_file_ids)\n                # Replace this with your actual chatbot logic\n\n                completion_thread = threading.Thread(target=self.get_completion_stream, args=(\n                    original_message, GradioEventHandler, message_file_ids, recipient_agent))\n                completion_thread.start()\n\n                message_file_ids = []\n                message_file_names = []\n\n                new_message = True\n                while True:\n                    try:\n                        bot_message = chatbot_queue.get(block=True)\n\n                        if bot_message == \"[end]\":\n                            completion_thread.join()\n                            break\n\n                        if bot_message == \"[new_message]\":\n                            new_message = True\n                            continue\n\n                        if new_message:\n                            history.append([None, bot_message])\n                            new_message = False\n                        else:\n                            history[-1][1] += bot_message\n\n                        yield \"\", history\n                    except queue.Empty:\n                        break\n\n            button.click(\n                user,\n                inputs=[msg, chatbot],\n                outputs=[msg, chatbot]\n            ).then(\n                bot, [msg, chatbot], [msg, chatbot]\n            )\n            dropdown.change(handle_dropdown_change, dropdown)\n            file_upload.change(handle_file_upload, file_upload)\n            msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n                bot, [msg, chatbot], [msg, chatbot]\n            )\n\n            # Enable queuing for streaming intermediate outputs\n            demo.queue()\n\n        # Launch the demo\n        demo.launch(**kwargs)\n        return demo\n\n    def _recipient_agent_completer(self, text, state):\n        \"\"\"\n        Autocomplete completer for recipient agent names.\n        \"\"\"\n        options = [agent for agent in self.recipient_agents if agent.lower().startswith(text.lower())]\n        if state &lt; len(options):\n            return options[state]\n        else:\n            return None\n\n    def _setup_autocomplete(self):\n        \"\"\"\n        Sets up readline with the completer function.\n        \"\"\"\n        try:\n            import readline\n        except ImportError:\n            # Attempt to import pyreadline for Windows compatibility\n            try:\n                import pyreadline as readline\n            except ImportError:\n                print(\n                    \"Module 'readline' not found. Autocomplete will not work. If you are using Windows, try installing 'pyreadline3'.\")\n                return\n\n        if not readline:\n            return\n\n        try:\n            readline.set_completer(self._recipient_agent_completer)\n            readline.parse_and_bind('tab: complete')\n        except Exception as e:\n            print(f\"Error setting up autocomplete for agents in terminal: {e}. Autocomplete will not work.\")\n\n    def run_demo(self):\n        \"\"\"\n        Executes agency in the terminal with autocomplete for recipient agent names.\n        \"\"\"\n        from agency_swarm import AgencyEventHandler\n        class TermEventHandler(AgencyEventHandler):\n            message_output = None\n\n            @override\n            def on_message_created(self, message: Message) -&gt; None:\n                if message.role == \"user\":\n                    self.message_output = MessageOutputLive(\"text\", self.agent_name, self.recipient_agent_name,\n                                                            \"\")\n                    self.message_output.cprint_update(message.content[0].text.value)\n                else:\n                    self.message_output = MessageOutputLive(\"text\", self.recipient_agent_name, self.agent_name, \"\")\n\n            @override\n            def on_message_done(self, message: Message) -&gt; None:\n                self.message_output = None\n\n            @override\n            def on_text_delta(self, delta, snapshot):\n                self.message_output.cprint_update(snapshot.value)\n\n            @override\n            def on_tool_call_created(self, tool_call):\n                # TODO: add support for code interpreter and retirieval tools\n\n                if tool_call.type == \"function\":\n                    self.message_output = MessageOutputLive(\"function\", self.recipient_agent_name, self.agent_name,\n                                                            str(tool_call.function))\n\n            @override\n            def on_tool_call_delta(self, delta, snapshot):\n                self.message_output.cprint_update(str(snapshot.function))\n\n            @override\n            def on_tool_call_done(self, snapshot):\n                self.message_output = None\n\n                # TODO: add support for code interpreter and retrieval tools\n                if snapshot.type != \"function\":\n                    return\n\n                if snapshot.function.name == \"SendMessage\":\n                    try:\n                        args = eval(snapshot.function.arguments)\n                        recipient = args[\"recipient\"]\n                        self.message_output = MessageOutputLive(\"text\", self.recipient_agent_name, recipient,\n                                                                \"\")\n\n                        self.message_output.cprint_update(args[\"message\"])\n                    except Exception as e:\n                        pass\n\n                self.message_output = None\n\n            @override\n            def on_run_step_done(self, run_step: RunStep) -&gt; None:\n                if run_step.type == \"tool_calls\":\n                    for tool_call in run_step.step_details.tool_calls:\n                        if tool_call.type != \"function\":\n                            continue\n\n                        if tool_call.function.name == \"SendMessage\":\n                            continue\n\n                        self.message_output = None\n                        self.message_output = MessageOutputLive(\"function_output\", tool_call.function.name,\n                                                                self.recipient_agent_name, tool_call.function.output)\n                        self.message_output.cprint_update(tool_call.function.output)\n\n                    self.message_output = None\n\n            @override\n            def on_end(self):\n                self.message_output = None\n\n        self.recipient_agents = [str(agent.name) for agent in self.main_recipients]\n\n        self._setup_autocomplete()  # Prepare readline for autocomplete\n\n        while True:\n            console.rule()\n            text = input(\"\ud83d\udc64 USER: \")\n\n            if not text:\n                continue\n\n            if text.lower() == \"exit\":\n                break\n\n            recipient_agent = None\n            if \"@\" in text:\n                recipient_agent = text.split(\"@\")[1].split(\" \")[0]\n                text = text.replace(f\"@{recipient_agent}\", \"\").strip()\n                try:\n                    recipient_agent = \\\n                        [agent for agent in self.recipient_agents if agent.lower() == recipient_agent.lower()][0]\n                    recipient_agent = self._get_agent_by_name(recipient_agent)\n                except Exception as e:\n                    print(f\"Recipient agent {recipient_agent} not found.\")\n                    continue\n\n            self.get_completion_stream(message=text, event_handler=TermEventHandler, recipient_agent=recipient_agent)\n\n    def get_customgpt_schema(self, url: str):\n        \"\"\"Returns the OpenAPI schema for the agency from the CEO agent, that you can use to integrate with custom gpts.\n\n        Parameters:\n            url (str): Your server url where the api will be hosted.\n        \"\"\"\n\n        return self.ceo.get_openapi_schema(url)\n\n    def plot_agency_chart(self):\n        pass\n\n    def _init_agents(self):\n        \"\"\"\n        Initializes all agents in the agency with unique IDs, shared instructions, and OpenAI models.\n\n        This method iterates through each agent in the agency, assigns a unique ID, adds shared instructions, and initializes the OpenAI models for each agent.\n\n        There are no input parameters.\n\n        There are no output parameters as this method is used for internal initialization purposes within the Agency class.\n        \"\"\"\n        if self.settings_callbacks:\n            loaded_settings = self.settings_callbacks[\"load\"]()\n            with open(self.settings_path, 'w') as f:\n                json.dump(loaded_settings, f, indent=4)\n\n        for agent in self.agents:\n            if \"temp_id\" in agent.id:\n                agent.id = None\n\n            agent.add_shared_instructions(self.shared_instructions)\n            agent.settings_path = self.settings_path\n\n            if self.shared_files:\n                if isinstance(self.shared_files, str):\n                    self.shared_files = [self.shared_files]\n\n                if isinstance(agent.files_folder, str):\n                    agent.files_folder = [agent.files_folder]\n                    agent.files_folder += self.shared_files\n                elif isinstance(agent.files_folder, list):\n                    agent.files_folder += self.shared_files\n\n            if self.temperature is not None and agent.temperature is None:\n                agent.temperature = self.temperature\n            if self.top_p and agent.top_p is None:\n                agent.top_p = self.top_p\n            if self.max_prompt_tokens is not None and agent.max_prompt_tokens is None:\n                agent.max_prompt_tokens = self.max_prompt_tokens\n            if self.max_completion_tokens is not None and agent.max_completion_tokens is None:\n                agent.max_completion_tokens = self.max_completion_tokens\n            if self.truncation_strategy is not None and agent.truncation_strategy is None:\n                agent.truncation_strategy = self.truncation_strategy\n\n            agent.init_oai()\n\n        if self.settings_callbacks:\n            with open(self.agents[0].get_settings_path(), 'r') as f:\n                settings = f.read()\n            settings = json.loads(settings)\n            self.settings_callbacks[\"save\"](settings)\n\n    def _init_threads(self):\n        \"\"\"\n        Initializes threads for communication between agents within the agency.\n\n        This method creates Thread objects for each pair of interacting agents as defined in the agents_and_threads attribute of the Agency. Each thread facilitates communication and task execution between an agent and its designated recipient agent.\n\n        No input parameters.\n\n        Output Parameters:\n            This method does not return any value but updates the agents_and_threads attribute with initialized Thread objects.\n        \"\"\"\n        self.main_thread = Thread(self.user, self.ceo)\n\n        # load thread ids\n        loaded_thread_ids = {}\n        if self.threads_callbacks:\n            loaded_thread_ids = self.threads_callbacks[\"load\"]()\n            if \"main_thread\" in loaded_thread_ids:\n                self.main_thread.id = loaded_thread_ids[\"main_thread\"]\n            else:\n                self.main_thread.init_thread()\n\n        for agent_name, threads in self.agents_and_threads.items():\n            for other_agent, items in threads.items():\n                self.agents_and_threads[agent_name][other_agent] = self.ThreadType(\n                    self._get_agent_by_name(items[\"agent\"]),\n                    self._get_agent_by_name(\n                        items[\"recipient_agent\"]))\n\n                if agent_name in loaded_thread_ids and other_agent in loaded_thread_ids[agent_name]:\n                    self.agents_and_threads[agent_name][other_agent].id = loaded_thread_ids[agent_name][other_agent]\n                elif self.threads_callbacks:\n                    self.agents_and_threads[agent_name][other_agent].init_thread()\n\n        # save thread ids\n        if self.threads_callbacks:\n            loaded_thread_ids = {}\n            for agent_name, threads in self.agents_and_threads.items():\n                loaded_thread_ids[agent_name] = {}\n                for other_agent, thread in threads.items():\n                    loaded_thread_ids[agent_name][other_agent] = thread.id\n\n            loaded_thread_ids[\"main_thread\"] = self.main_thread.id\n\n            self.threads_callbacks[\"save\"](loaded_thread_ids)\n\n    def _parse_agency_chart(self, agency_chart):\n        \"\"\"\n        Parses the provided agency chart to initialize and organize agents within the agency.\n\n        Parameters:\n            agency_chart: A structure representing the hierarchical organization of agents within the agency.\n                    It can contain Agent objects and lists of Agent objects.\n\n        This method iterates through each node in the agency chart. If a node is an Agent, it is set as the CEO if not already assigned.\n        If a node is a list, it iterates through the agents in the list, adding them to the agency and establishing communication\n        threads between them. It raises an exception if the agency chart is invalid or if multiple CEOs are defined.\n        \"\"\"\n        if not isinstance(agency_chart, list):\n            raise Exception(\"Invalid agency chart.\")\n\n        if len(agency_chart) == 0:\n            raise Exception(\"Agency chart cannot be empty.\")\n\n        for node in agency_chart:\n            if isinstance(node, Agent):\n                if not self.ceo:\n                    self.ceo = node\n                    self._add_agent(self.ceo)\n                else:\n                    self._add_agent(node)\n                self._add_main_recipient(node)\n\n            elif isinstance(node, list):\n                for i, agent in enumerate(node):\n                    if not isinstance(agent, Agent):\n                        raise Exception(\"Invalid agency chart.\")\n\n                    index = self._add_agent(agent)\n\n                    if i == len(node) - 1:\n                        continue\n\n                    if agent.name not in self.agents_and_threads.keys():\n                        self.agents_and_threads[agent.name] = {}\n\n                    if i &lt; len(node) - 1:\n                        other_agent = node[i + 1]\n                        if other_agent.name == agent.name:\n                            continue\n                        if other_agent.name not in self.agents_and_threads[agent.name].keys():\n                            self.agents_and_threads[agent.name][other_agent.name] = {\n                                \"agent\": agent.name,\n                                \"recipient_agent\": other_agent.name,\n                            }\n            else:\n                raise Exception(\"Invalid agency chart.\")\n\n    def _add_agent(self, agent):\n        \"\"\"\n        Adds an agent to the agency, assigning a temporary ID if necessary.\n\n        Parameters:\n            agent (Agent): The agent to be added to the agency.\n\n        Returns:\n            int: The index of the added agent within the agency's agents list.\n\n        This method adds an agent to the agency's list of agents. If the agent does not have an ID, it assigns a temporary unique ID. It checks for uniqueness of the agent's name before addition. The method returns the index of the agent in the agency's agents list, which is used for referencing the agent within the agency.\n        \"\"\"\n        if not agent.id:\n            # assign temp id\n            agent.id = \"temp_id_\" + str(uuid.uuid4())\n        if agent.id not in self._get_agent_ids():\n            if agent.name in self._get_agent_names():\n                raise Exception(\"Agent names must be unique.\")\n            self.agents.append(agent)\n            return len(self.agents) - 1\n        else:\n            return self._get_agent_ids().index(agent.id)\n\n    def _add_main_recipient(self, agent):\n        \"\"\"\n        Adds an agent to the agency's list of main recipients.\n\n        Parameters:\n            agent (Agent): The agent to be added to the agency's list of main recipients.\n\n        This method adds an agent to the agency's list of main recipients. These are agents that can be directly contacted by the user.\n        \"\"\"\n        main_recipient_ids = [agent.id for agent in self.main_recipients]\n\n        if agent.id not in main_recipient_ids:\n            self.main_recipients.append(agent)\n\n    def _read_instructions(self, path):\n        \"\"\"\n        Reads shared instructions from a specified file and stores them in the agency.\n\n        Parameters:\n            path (str): The file path from which to read the shared instructions.\n\n        This method opens the file located at the given path, reads its contents, and stores these contents in the 'shared_instructions' attribute of the agency. This is used to provide common guidelines or instructions to all agents within the agency.\n        \"\"\"\n        path = path\n        with open(path, 'r') as f:\n            self.shared_instructions = f.read()\n\n    def _create_special_tools(self):\n        \"\"\"\n        Creates and assigns 'SendMessage' tools to each agent based on the agency's structure.\n\n        This method iterates through the agents and threads in the agency, creating SendMessage tools for each agent. These tools enable agents to send messages to other agents as defined in the agency's structure. The SendMessage tools are tailored to the specific recipient agents that each agent can communicate with.\n\n        No input parameters.\n\n        No output parameters; this method modifies the agents' toolset internally.\n        \"\"\"\n        for agent_name, threads in self.agents_and_threads.items():\n            recipient_names = list(threads.keys())\n            recipient_agents = self._get_agents_by_names(recipient_names)\n            if len(recipient_agents) == 0:\n                continue\n            agent = self._get_agent_by_name(agent_name)\n            agent.add_tool(self._create_send_message_tool(agent, recipient_agents))\n            if self.async_mode:\n                agent.add_tool(self._create_get_response_tool(agent, recipient_agents))\n\n    def _create_send_message_tool(self, agent: Agent, recipient_agents: List[Agent]):\n        \"\"\"\n        Creates a SendMessage tool to enable an agent to send messages to specified recipient agents.\n\n\n        Parameters:\n            agent (Agent): The agent who will be sending messages.\n            recipient_agents (List[Agent]): A list of recipient agents who can receive messages.\n\n        Returns:\n            SendMessage: A SendMessage tool class that is dynamically created and configured for the given agent and its recipient agents. This tool allows the agent to send messages to the specified recipients, facilitating inter-agent communication within the agency.\n        \"\"\"\n        recipient_names = [agent.name for agent in recipient_agents]\n        recipients = Enum(\"recipient\", {name: name for name in recipient_names})\n\n        agent_descriptions = \"\"\n        for recipient_agent in recipient_agents:\n            if not recipient_agent.description:\n                continue\n            agent_descriptions += recipient_agent.name + \": \"\n            agent_descriptions += recipient_agent.description + \"\\n\"\n\n        outer_self = self\n\n        class SendMessage(BaseTool):\n            my_primary_instructions: str = Field(...,\n                                                 description=\"Please repeat your primary instructions step-by-step, including both completed \"\n                                                             \"and the following next steps that you need to perfrom. For multi-step, complex tasks, first break them down \"\n                                                             \"into smaller steps yourself. Then, issue each step individually to the \"\n                                                             \"recipient agent via the message parameter. Each identified step should be \"\n                                                             \"sent in separate message. Keep in mind, that the recipient agent does not have access \"\n                                                             \"to these instructions. You must include recipient agent-specific instructions \"\n                                                             \"in the message or additional_instructions parameters.\")\n            recipient: recipients = Field(..., description=agent_descriptions)\n            message: str = Field(...,\n                                 description=\"Specify the task required for the recipient agent to complete. Focus on \"\n                                             \"clarifying what the task entails, rather than providing exact \"\n                                             \"instructions.\")\n            message_files: Optional[List[str]] = Field(default=None,\n                                                       description=\"A list of file ids to be sent as attachments to this message. Only use this if you have the file id that starts with 'file-'.\",\n                                                       examples=[\"file-1234\", \"file-5678\"])\n            additional_instructions: str = Field(default=None,\n                                                 description=\"Any additional instructions or clarifications that you would like to provide to the recipient agent.\")\n            one_call_at_a_time: bool = True\n\n            @model_validator(mode='after')\n            def validate_files(self):\n                if \"file-\" in self.message or (\n                        self.additional_instructions and \"file-\" in self.additional_instructions):\n                    if not self.message_files:\n                        raise ValueError(\"You must include file ids in message_files parameter.\")\n\n            @field_validator('recipient')\n            def check_recipient(cls, value):\n                if value.value not in recipient_names:\n                    raise ValueError(f\"Recipient {value} is not valid. Valid recipients are: {recipient_names}\")\n                return value\n\n            def run(self):\n                thread = outer_self.agents_and_threads[self.caller_agent.name][self.recipient.value]\n\n                if not outer_self.async_mode:\n                    message = thread.get_completion(message=self.message,\n                                                    message_files=self.message_files,\n                                                    event_handler=self.event_handler,\n                                                    additional_instructions=self.additional_instructions)\n                else:\n                    message = thread.get_completion_async(message=self.message,\n                                                          message_files=self.message_files,\n                                                          additional_instructions=self.additional_instructions)\n\n                return message or \"\"\n\n        SendMessage.caller_agent = agent\n        if self.async_mode:\n            SendMessage.__doc__ = self.send_message_tool_description_async\n        else:\n            SendMessage.__doc__ = self.send_message_tool_description\n\n        return SendMessage\n\n    def _create_get_response_tool(self, agent: Agent, recipient_agents: List[Agent]):\n        \"\"\"\n        Creates a CheckStatus tool to enable an agent to check the status of a task with a specified recipient agent.\n        \"\"\"\n        recipient_names = [agent.name for agent in recipient_agents]\n        recipients = Enum(\"recipient\", {name: name for name in recipient_names})\n\n        outer_self = self\n\n        class GetResponse(BaseTool):\n            \"\"\"This tool allows you to check the status of a task or get a response from a specified recipient agent, if the task has been completed. You must always use 'SendMessage' tool with the designated agent first.\"\"\"\n            recipient: recipients = Field(...,\n                                          description=f\"Recipient agent that you want to check the status of. Valid recipients are: {recipient_names}\")\n\n            @field_validator('recipient')\n            def check_recipient(cls, value):\n                if value.value not in recipient_names:\n                    raise ValueError(f\"Recipient {value} is not valid. Valid recipients are: {recipient_names}\")\n                return value\n\n            def run(self):\n                thread = outer_self.agents_and_threads[self.caller_agent.name][self.recipient.value]\n\n                return thread.check_status()\n\n        GetResponse.caller_agent = agent\n\n        return GetResponse\n\n    def _get_agent_by_name(self, agent_name):\n        \"\"\"\n        Retrieves an agent from the agency based on the agent's name.\n\n        Parameters:\n            agent_name (str): The name of the agent to be retrieved.\n\n        Returns:\n            Agent: The agent object with the specified name.\n\n        Raises:\n            Exception: If no agent with the given name is found in the agency.\n        \"\"\"\n        for agent in self.agents:\n            if agent.name == agent_name:\n                return agent\n        raise Exception(f\"Agent {agent_name} not found.\")\n\n    def _get_agents_by_names(self, agent_names):\n        \"\"\"\n        Retrieves a list of agent objects based on their names.\n\n        Parameters:\n            agent_names: A list of strings representing the names of the agents to be retrieved.\n\n        Returns:\n            A list of Agent objects corresponding to the given names.\n        \"\"\"\n        return [self._get_agent_by_name(agent_name) for agent_name in agent_names]\n\n    def _get_agent_ids(self):\n        \"\"\"\n        Retrieves the IDs of all agents currently in the agency.\n\n        Returns:\n            List[str]: A list containing the unique IDs of all agents.\n        \"\"\"\n        return [agent.id for agent in self.agents]\n\n    def _get_agent_names(self):\n        \"\"\"\n        Retrieves the names of all agents in the agency.\n\n        Returns:\n            List[str]: A list of names of all agents currently part of the agency.\n        \"\"\"\n        return [agent.name for agent in self.agents]\n\n    def _get_class_folder_path(self):\n        \"\"\"\n        Retrieves the absolute path of the directory containing the class file.\n\n        Returns:\n            str: The absolute path of the directory where the class file is located.\n        \"\"\"\n        return os.path.abspath(os.path.dirname(inspect.getfile(self.__class__)))\n\n    def delete(self):\n        \"\"\"\n        This method deletes the agency and all its agents, cleaning up any files and vector stores associated with each agent.\n        \"\"\"\n        for agent in self.agents:\n            agent.delete()\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.__init__","title":"<code>__init__(agency_chart, shared_instructions='', shared_files=None, async_mode=None, settings_path='./settings.json', settings_callbacks=None, threads_callbacks=None, temperature=0.3, top_p=1.0, max_prompt_tokens=None, max_completion_tokens=None, truncation_strategy=None)</code>","text":"<p>Initializes the Agency object, setting up agents, threads, and core functionalities.</p> <p>Parameters:</p> Name Type Description Default <code>agency_chart</code> <code>List</code> <p>The structure defining the hierarchy and interaction of agents within the agency.</p> required <code>shared_instructions</code> <code>str</code> <p>A path to a file containing shared instructions for all agents. Defaults to an empty string.</p> <code>''</code> <code>shared_files</code> <code>Union[str, List[str]]</code> <p>A path to a folder or a list of folders containing shared files for all agents. Defaults to None.</p> <code>None</code> <code>async_mode</code> <code>str</code> <p>The mode for asynchronous message processing. Defaults to None.</p> <code>None</code> <code>settings_path</code> <code>str</code> <p>The path to the settings file for the agency. Must be json. If file does not exist, it will be created. Defaults to None.</p> <code>'./settings.json'</code> <code>settings_callbacks</code> <code>SettingsCallbacks</code> <p>A dictionary containing functions to load and save settings for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.</p> <code>None</code> <code>threads_callbacks</code> <code>ThreadsCallbacks</code> <p>A dictionary containing functions to load and save threads for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.</p> <code>None</code> <code>temperature</code> <code>float</code> <p>The temperature value to use for the agents. Agent specific values will override this. Defaults to 0.3.</p> <code>0.3</code> <code>top_p</code> <code>float</code> <p>The top_p value to use for the agents. Agent specific values will override this. Defaults to None.</p> <code>1.0</code> <code>max_prompt_tokens</code> <code>int</code> <p>The maximum number of tokens allowed in the prompt for each agent. Agent specific values will override this. Defaults to None.</p> <code>None</code> <code>max_completion_tokens</code> <code>int</code> <p>The maximum number of tokens allowed in the completion for each agent. Agent specific values will override this. Defaults to None.</p> <code>None</code> <code>truncation_strategy</code> <code>dict</code> <p>The truncation strategy to use for the completion for each agent. Agent specific values will override this. Defaults to None.</p> <code>None</code> <p>This constructor initializes various components of the Agency, including CEO, agents, threads, and user interactions. It parses the agency chart to set up the organizational structure and initializes the messaging tools, agents, and threads necessary for the operation of the agency. Additionally, it prepares a main thread for user interactions.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def __init__(self,\n             agency_chart: List,\n             shared_instructions: str = \"\",\n             shared_files: Union[str, List[str]] = None,\n             async_mode: Literal['threading'] = None,\n             settings_path: str = \"./settings.json\",\n             settings_callbacks: SettingsCallbacks = None,\n             threads_callbacks: ThreadsCallbacks = None,\n             temperature: float = 0.3,\n             top_p: float = 1.0,\n             max_prompt_tokens: int = None,\n             max_completion_tokens: int = None,\n             truncation_strategy: dict = None,\n             ):\n    \"\"\"\n    Initializes the Agency object, setting up agents, threads, and core functionalities.\n\n    Parameters:\n        agency_chart: The structure defining the hierarchy and interaction of agents within the agency.\n        shared_instructions (str, optional): A path to a file containing shared instructions for all agents. Defaults to an empty string.\n        shared_files (Union[str, List[str]], optional): A path to a folder or a list of folders containing shared files for all agents. Defaults to None.\n        async_mode (str, optional): The mode for asynchronous message processing. Defaults to None.\n        settings_path (str, optional): The path to the settings file for the agency. Must be json. If file does not exist, it will be created. Defaults to None.\n        settings_callbacks (SettingsCallbacks, optional): A dictionary containing functions to load and save settings for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.\n        threads_callbacks (ThreadsCallbacks, optional): A dictionary containing functions to load and save threads for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.\n        temperature (float, optional): The temperature value to use for the agents. Agent specific values will override this. Defaults to 0.3.\n        top_p (float, optional): The top_p value to use for the agents. Agent specific values will override this. Defaults to None.\n        max_prompt_tokens (int, optional): The maximum number of tokens allowed in the prompt for each agent. Agent specific values will override this. Defaults to None.\n        max_completion_tokens (int, optional): The maximum number of tokens allowed in the completion for each agent. Agent specific values will override this. Defaults to None.\n        truncation_strategy (dict, optional): The truncation strategy to use for the completion for each agent. Agent specific values will override this. Defaults to None.\n\n    This constructor initializes various components of the Agency, including CEO, agents, threads, and user interactions. It parses the agency chart to set up the organizational structure and initializes the messaging tools, agents, and threads necessary for the operation of the agency. Additionally, it prepares a main thread for user interactions.\n    \"\"\"\n    self.async_mode = async_mode\n    if self.async_mode == \"threading\":\n        from agency_swarm.threads.thread_async import ThreadAsync\n        self.ThreadType = ThreadAsync\n\n    self.ceo = None\n    self.user = User()\n    self.agents = []\n    self.agents_and_threads = {}\n    self.main_recipients = []\n    self.main_thread = None\n    self.recipient_agents = None  # for autocomplete\n    self.shared_files = shared_files if shared_files else []\n    self.settings_path = settings_path\n    self.settings_callbacks = settings_callbacks\n    self.threads_callbacks = threads_callbacks\n    self.temperature = temperature\n    self.top_p = top_p\n    self.max_prompt_tokens = max_prompt_tokens\n    self.max_completion_tokens = max_completion_tokens\n    self.truncation_strategy = truncation_strategy\n\n    if os.path.isfile(os.path.join(self._get_class_folder_path(), shared_instructions)):\n        self._read_instructions(os.path.join(self._get_class_folder_path(), shared_instructions))\n    elif os.path.isfile(shared_instructions):\n        self._read_instructions(shared_instructions)\n    else:\n        self.shared_instructions = shared_instructions\n\n    self._parse_agency_chart(agency_chart)\n    self._create_special_tools()\n    self._init_agents()\n    self._init_threads()\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.delete","title":"<code>delete()</code>","text":"<p>This method deletes the agency and all its agents, cleaning up any files and vector stores associated with each agent.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def delete(self):\n    \"\"\"\n    This method deletes the agency and all its agents, cleaning up any files and vector stores associated with each agent.\n    \"\"\"\n    for agent in self.agents:\n        agent.delete()\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.demo_gradio","title":"<code>demo_gradio(height=450, dark_mode=True, **kwargs)</code>","text":"<p>Launches a Gradio-based demo interface for the agency chatbot.</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>The height of the chatbot widget in the Gradio interface. Default is 600.</p> <code>450</code> <code>dark_mode</code> <code>bool</code> <p>Flag to determine if the interface should be displayed in dark mode. Default is True.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to the Gradio interface.</p> <code>{}</code> <p>This method sets up and runs a Gradio interface, allowing users to interact with the agency's chatbot. It includes a text input for the user's messages and a chatbot interface for displaying the conversation. The method handles user input and chatbot responses, updating the interface dynamically.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def demo_gradio(self, height=450, dark_mode=True, **kwargs):\n    \"\"\"\n    Launches a Gradio-based demo interface for the agency chatbot.\n\n    Parameters:\n        height (int, optional): The height of the chatbot widget in the Gradio interface. Default is 600.\n        dark_mode (bool, optional): Flag to determine if the interface should be displayed in dark mode. Default is True.\n        **kwargs: Additional keyword arguments to be passed to the Gradio interface.\n    This method sets up and runs a Gradio interface, allowing users to interact with the agency's chatbot. It includes a text input for the user's messages and a chatbot interface for displaying the conversation. The method handles user input and chatbot responses, updating the interface dynamically.\n    \"\"\"\n\n    try:\n        import gradio as gr\n    except ImportError:\n        raise Exception(\"Please install gradio: pip install gradio\")\n\n    js = \"\"\"function () {\n      gradioURL = window.location.href\n      if (!gradioURL.endsWith('?__theme={theme}')) {\n        window.location.replace(gradioURL + '?__theme={theme}');\n      }\n    }\"\"\"\n\n    if dark_mode:\n        js = js.replace(\"{theme}\", \"dark\")\n    else:\n        js = js.replace(\"{theme}\", \"light\")\n\n    message_file_ids = []\n    message_file_names = None\n    recipient_agents = [agent.name for agent in self.main_recipients]\n    recipient_agent = self.main_recipients[0]\n\n    with gr.Blocks(js=js) as demo:\n        chatbot_queue = queue.Queue()\n        chatbot = gr.Chatbot(height=height)\n        with gr.Row():\n            with gr.Column(scale=9):\n                dropdown = gr.Dropdown(label=\"Recipient Agent\", choices=recipient_agents,\n                                       value=recipient_agent.name)\n                msg = gr.Textbox(label=\"Your Message\", lines=4)\n            with gr.Column(scale=1):\n                file_upload = gr.Files(label=\"Files\", type=\"filepath\")\n        button = gr.Button(value=\"Send\", variant=\"primary\")\n\n        def handle_dropdown_change(selected_option):\n            nonlocal recipient_agent\n            recipient_agent = self._get_agent_by_name(selected_option)\n\n        def handle_file_upload(file_list):\n            nonlocal message_file_ids\n            nonlocal message_file_names\n            message_file_ids = []\n            message_file_names = []\n            if file_list:\n                try:\n                    for file_obj in file_list:\n                        with open(file_obj.name, 'rb') as f:\n                            # Upload the file to OpenAI\n                            file = self.main_thread.client.files.create(\n                                file=f,\n                                purpose=\"assistants\"\n                            )\n                        message_file_ids.append(file.id)\n                        message_file_names.append(file.filename)\n                        print(f\"Uploaded file ID: {file.id}\")\n                    return message_file_ids\n                except Exception as e:\n                    print(f\"Error: {e}\")\n                    return str(e)\n\n            return \"No files uploaded\"\n\n        def user(user_message, history):\n            if history is None:\n                history = []\n\n            original_user_message = user_message\n\n            # Append the user message with a placeholder for bot response\n            if recipient_agent:\n                user_message = f\"\ud83d\udc64 User \ud83d\udde3\ufe0f @{recipient_agent.name}:\\n\" + user_message.strip()\n            else:\n                user_message = f\"\ud83d\udc64 User:\" + user_message.strip()\n\n            nonlocal message_file_names\n            if message_file_names:\n                user_message += \"\\n\\n\ud83d\udcce Files:\\n\" + \"\\n\".join(message_file_names)\n\n            return original_user_message, history + [[user_message, None]]\n\n        class GradioEventHandler(AgencyEventHandler):\n            message_output = None\n\n            @override\n            def on_message_created(self, message: Message) -&gt; None:\n                if message.role == \"user\":\n                    self.message_output = MessageOutput(\"text\", self.agent_name, self.recipient_agent_name,\n                                                        message.content[0].text.value)\n\n                else:\n                    self.message_output = MessageOutput(\"text\", self.recipient_agent_name, self.agent_name,\n                                                        \"\")\n\n                chatbot_queue.put(\"[new_message]\")\n                chatbot_queue.put(self.message_output.get_formatted_content())\n\n            @override\n            def on_text_delta(self, delta, snapshot):\n                chatbot_queue.put(delta.value)\n\n            @override\n            def on_tool_call_created(self, tool_call):\n                # TODO: add support for code interpreter and retirieval tools\n                if tool_call.type == \"function\":\n                    chatbot_queue.put(\"[new_message]\")\n                    self.message_output = MessageOutput(\"function\", self.recipient_agent_name, self.agent_name,\n                                                        str(tool_call.function))\n                    chatbot_queue.put(self.message_output.get_formatted_header() + \"\\n\")\n\n            @override\n            def on_tool_call_done(self, snapshot):\n                self.message_output = None\n\n                # TODO: add support for code interpreter and retirieval tools\n                if snapshot.type != \"function\":\n                    return\n\n                chatbot_queue.put(str(snapshot.function))\n\n                if snapshot.function.name == \"SendMessage\":\n                    try:\n                        args = eval(snapshot.function.arguments)\n                        recipient = args[\"recipient\"]\n                        self.message_output = MessageOutput(\"text\", self.recipient_agent_name, recipient,\n                                                            args[\"message\"])\n\n                        chatbot_queue.put(\"[new_message]\")\n                        chatbot_queue.put(self.message_output.get_formatted_content())\n                    except Exception as e:\n                        pass\n\n                self.message_output = None\n\n            @override\n            def on_run_step_done(self, run_step: RunStep) -&gt; None:\n                if run_step.type == \"tool_calls\":\n                    for tool_call in run_step.step_details.tool_calls:\n                        if tool_call.type != \"function\":\n                            continue\n\n                        if tool_call.function.name == \"SendMessage\":\n                            continue\n\n                        self.message_output = None\n                        chatbot_queue.put(\"[new_message]\")\n\n                        self.message_output = MessageOutput(\"function_output\", tool_call.function.name,\n                                                            self.recipient_agent_name,\n                                                            tool_call.function.output)\n\n                        chatbot_queue.put(self.message_output.get_formatted_header() + \"\\n\")\n                        chatbot_queue.put(tool_call.function.output)\n\n            @override\n            @classmethod\n            def on_all_streams_end(cls):\n                self.message_output = None\n                chatbot_queue.put(\"[end]\")\n\n        def bot(original_message, history):\n            nonlocal message_file_ids\n            nonlocal message_file_names\n            nonlocal recipient_agent\n            print(\"Message files: \", message_file_ids)\n            # Replace this with your actual chatbot logic\n\n            completion_thread = threading.Thread(target=self.get_completion_stream, args=(\n                original_message, GradioEventHandler, message_file_ids, recipient_agent))\n            completion_thread.start()\n\n            message_file_ids = []\n            message_file_names = []\n\n            new_message = True\n            while True:\n                try:\n                    bot_message = chatbot_queue.get(block=True)\n\n                    if bot_message == \"[end]\":\n                        completion_thread.join()\n                        break\n\n                    if bot_message == \"[new_message]\":\n                        new_message = True\n                        continue\n\n                    if new_message:\n                        history.append([None, bot_message])\n                        new_message = False\n                    else:\n                        history[-1][1] += bot_message\n\n                    yield \"\", history\n                except queue.Empty:\n                    break\n\n        button.click(\n            user,\n            inputs=[msg, chatbot],\n            outputs=[msg, chatbot]\n        ).then(\n            bot, [msg, chatbot], [msg, chatbot]\n        )\n        dropdown.change(handle_dropdown_change, dropdown)\n        file_upload.change(handle_file_upload, file_upload)\n        msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n            bot, [msg, chatbot], [msg, chatbot]\n        )\n\n        # Enable queuing for streaming intermediate outputs\n        demo.queue()\n\n    # Launch the demo\n    demo.launch(**kwargs)\n    return demo\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.get_completion","title":"<code>get_completion(message, message_files=None, yield_messages=False, recipient_agent=None, additional_instructions=None, attachments=None, tool_choice=None)</code>","text":"<p>Retrieves the completion for a given message from the main thread.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message for which completion is to be retrieved.</p> required <code>message_files</code> <code>list</code> <p>A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.</p> <code>None</code> <code>yield_messages</code> <code>bool</code> <p>Flag to determine if intermediate messages should be yielded. Defaults to True.</p> <code>False</code> <code>recipient_agent</code> <code>Agent</code> <p>The agent to which the message should be sent. Defaults to the first agent in the agency chart.</p> <code>None</code> <code>additional_instructions</code> <code>str</code> <p>Additional instructions to be sent with the message. Defaults to None.</p> <code>None</code> <code>attachments</code> <code>List[dict]</code> <p>A list of attachments to be sent with the message, following openai format. Defaults to None.</p> <code>None</code> <code>tool_choice</code> <code>dict</code> <p>The tool choice for the recipient agent to use. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>Generator or final response: Depending on the 'yield_messages' flag, this method returns either a generator yielding intermediate messages or the final response from the main thread.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def get_completion(self, message: str,\n                   message_files: List[str] = None,\n                   yield_messages: bool = False,\n                   recipient_agent: Agent = None,\n                   additional_instructions: str = None,\n                   attachments: List[dict] = None,\n                   tool_choice: dict = None,\n                   ):\n    \"\"\"\n    Retrieves the completion for a given message from the main thread.\n\n    Parameters:\n        message (str): The message for which completion is to be retrieved.\n        message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n        yield_messages (bool, optional): Flag to determine if intermediate messages should be yielded. Defaults to True.\n        recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n        additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n        attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n        tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n\n    Returns:\n        Generator or final response: Depending on the 'yield_messages' flag, this method returns either a generator yielding intermediate messages or the final response from the main thread.\n    \"\"\"\n    if yield_messages:\n        print(\"Warning: yield_messages parameter is deprecated. Use streaming instead.\")\n\n    return self.main_thread.get_completion(message=message,\n                                           message_files=message_files,\n                                           attachments=attachments,\n                                           recipient_agent=recipient_agent,\n                                           additional_instructions=additional_instructions,\n                                           tool_choice=tool_choice)\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.get_completion_stream","title":"<code>get_completion_stream(message, event_handler, message_files=None, recipient_agent=None, additional_instructions=None, attachments=None, tool_choice=None)</code>","text":"<p>Generates a stream of completions for a given message from the main thread.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message for which completion is to be retrieved.</p> required <code>event_handler</code> <code>type(AgencyEventHandler</code> <p>The event handler class to handle the completion stream. https://github.com/openai/openai-python/blob/main/helpers.md</p> required <code>message_files</code> <code>list</code> <p>A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.</p> <code>None</code> <code>recipient_agent</code> <code>Agent</code> <p>The agent to which the message should be sent. Defaults to the first agent in the agency chart.</p> <code>None</code> <code>additional_instructions</code> <code>str</code> <p>Additional instructions to be sent with the message. Defaults to None.</p> <code>None</code> <code>attachments</code> <code>List[dict]</code> <p>A list of attachments to be sent with the message, following openai format. Defaults to None.</p> <code>None</code> <code>tool_choice</code> <code>dict</code> <p>The tool choice for the recipient agent to use. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>Final response: Final response from the main thread.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def get_completion_stream(self,\n                          message: str,\n                          event_handler: type(AgencyEventHandler),\n                          message_files: List[str] = None,\n                          recipient_agent: Agent = None,\n                          additional_instructions: str = None,\n                          attachments: List[dict] = None,\n                          tool_choice: dict = None\n                          ):\n    \"\"\"\n    Generates a stream of completions for a given message from the main thread.\n\n    Parameters:\n        message (str): The message for which completion is to be retrieved.\n        event_handler (type(AgencyEventHandler)): The event handler class to handle the completion stream. https://github.com/openai/openai-python/blob/main/helpers.md\n        message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n        recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n        additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n        attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n        tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n\n    Returns:\n        Final response: Final response from the main thread.\n    \"\"\"\n    if self.async_mode:\n        raise Exception(\"Streaming is not supported in async mode.\")\n\n    if not inspect.isclass(event_handler):\n        raise Exception(\"Event handler must not be an instance.\")\n\n    res = self.main_thread.get_completion_stream(message=message,\n                                                  message_files=message_files,\n                                                  event_handler=event_handler,\n                                                  attachments=attachments,\n                                                  recipient_agent=recipient_agent,\n                                                  additional_instructions=additional_instructions,\n                                                  tool_choice=tool_choice\n                                                  )\n\n    event_handler.on_all_streams_end()\n\n    return res\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.get_customgpt_schema","title":"<code>get_customgpt_schema(url)</code>","text":"<p>Returns the OpenAPI schema for the agency from the CEO agent, that you can use to integrate with custom gpts.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Your server url where the api will be hosted.</p> required Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def get_customgpt_schema(self, url: str):\n    \"\"\"Returns the OpenAPI schema for the agency from the CEO agent, that you can use to integrate with custom gpts.\n\n    Parameters:\n        url (str): Your server url where the api will be hosted.\n    \"\"\"\n\n    return self.ceo.get_openapi_schema(url)\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.run_demo","title":"<code>run_demo()</code>","text":"<p>Executes agency in the terminal with autocomplete for recipient agent names.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def run_demo(self):\n    \"\"\"\n    Executes agency in the terminal with autocomplete for recipient agent names.\n    \"\"\"\n    from agency_swarm import AgencyEventHandler\n    class TermEventHandler(AgencyEventHandler):\n        message_output = None\n\n        @override\n        def on_message_created(self, message: Message) -&gt; None:\n            if message.role == \"user\":\n                self.message_output = MessageOutputLive(\"text\", self.agent_name, self.recipient_agent_name,\n                                                        \"\")\n                self.message_output.cprint_update(message.content[0].text.value)\n            else:\n                self.message_output = MessageOutputLive(\"text\", self.recipient_agent_name, self.agent_name, \"\")\n\n        @override\n        def on_message_done(self, message: Message) -&gt; None:\n            self.message_output = None\n\n        @override\n        def on_text_delta(self, delta, snapshot):\n            self.message_output.cprint_update(snapshot.value)\n\n        @override\n        def on_tool_call_created(self, tool_call):\n            # TODO: add support for code interpreter and retirieval tools\n\n            if tool_call.type == \"function\":\n                self.message_output = MessageOutputLive(\"function\", self.recipient_agent_name, self.agent_name,\n                                                        str(tool_call.function))\n\n        @override\n        def on_tool_call_delta(self, delta, snapshot):\n            self.message_output.cprint_update(str(snapshot.function))\n\n        @override\n        def on_tool_call_done(self, snapshot):\n            self.message_output = None\n\n            # TODO: add support for code interpreter and retrieval tools\n            if snapshot.type != \"function\":\n                return\n\n            if snapshot.function.name == \"SendMessage\":\n                try:\n                    args = eval(snapshot.function.arguments)\n                    recipient = args[\"recipient\"]\n                    self.message_output = MessageOutputLive(\"text\", self.recipient_agent_name, recipient,\n                                                            \"\")\n\n                    self.message_output.cprint_update(args[\"message\"])\n                except Exception as e:\n                    pass\n\n            self.message_output = None\n\n        @override\n        def on_run_step_done(self, run_step: RunStep) -&gt; None:\n            if run_step.type == \"tool_calls\":\n                for tool_call in run_step.step_details.tool_calls:\n                    if tool_call.type != \"function\":\n                        continue\n\n                    if tool_call.function.name == \"SendMessage\":\n                        continue\n\n                    self.message_output = None\n                    self.message_output = MessageOutputLive(\"function_output\", tool_call.function.name,\n                                                            self.recipient_agent_name, tool_call.function.output)\n                    self.message_output.cprint_update(tool_call.function.output)\n\n                self.message_output = None\n\n        @override\n        def on_end(self):\n            self.message_output = None\n\n    self.recipient_agents = [str(agent.name) for agent in self.main_recipients]\n\n    self._setup_autocomplete()  # Prepare readline for autocomplete\n\n    while True:\n        console.rule()\n        text = input(\"\ud83d\udc64 USER: \")\n\n        if not text:\n            continue\n\n        if text.lower() == \"exit\":\n            break\n\n        recipient_agent = None\n        if \"@\" in text:\n            recipient_agent = text.split(\"@\")[1].split(\" \")[0]\n            text = text.replace(f\"@{recipient_agent}\", \"\").strip()\n            try:\n                recipient_agent = \\\n                    [agent for agent in self.recipient_agents if agent.lower() == recipient_agent.lower()][0]\n                recipient_agent = self._get_agent_by_name(recipient_agent)\n            except Exception as e:\n                print(f\"Recipient agent {recipient_agent} not found.\")\n                continue\n\n        self.get_completion_stream(message=text, event_handler=TermEventHandler, recipient_agent=recipient_agent)\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory","title":"<code>ToolFactory</code>","text":"Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>class ToolFactory:\n\n    @staticmethod\n    def from_langchain_tools(tools: List) -&gt; List[Type[BaseTool]]:\n        \"\"\"\n        Converts a list of langchain tools into a list of BaseTools.\n\n        Parameters:\n            tools: The langchain tools to convert.\n\n        Returns:\n            A list of BaseTools.\n        \"\"\"\n        converted_tools = []\n        for tool in tools:\n            converted_tools.append(ToolFactory.from_langchain_tool(tool))\n\n        return converted_tools\n\n    @staticmethod\n    def from_langchain_tool(tool) -&gt; Type[BaseTool]:\n        \"\"\"\n        Converts a langchain tool into a BaseTool.\n\n        Parameters:\n            tool: The langchain tool to convert.\n\n        Returns:\n            A BaseTool.\n        \"\"\"\n        try:\n            from langchain.tools import format_tool_to_openai_function\n        except ImportError:\n            raise ImportError(\"You must install langchain to use this method.\")\n\n        if inspect.isclass(tool):\n            tool = tool()\n\n        def callback(self):\n            tool_input = self.model_dump()\n            try:\n                return tool.run(tool_input)\n            except TypeError:\n                if len(tool_input) == 1:\n                    return tool.run(list(tool_input.values())[0])\n                else:\n                    raise TypeError(f\"Error parsing input for tool '{tool.__class__.__name__}' Please open an issue \"\n                                    f\"on github.\")\n\n        return ToolFactory.from_openai_schema(\n            format_tool_to_openai_function(tool),\n            callback\n        )\n\n\n    @staticmethod\n    def from_openai_schema(schema: Dict[str, Any], callback: Any) -&gt; Type[BaseTool]:\n        \"\"\"\n        Converts an OpenAI schema into a BaseTool. Nested propoerties without refs are not supported yet.\n\n        Parameters:\n            schema: The OpenAI schema to convert.\n            callback: The function to run when the tool is called.\n\n        Returns:\n            A BaseTool.\n        \"\"\"\n        def resolve_ref(ref: str, defs: Dict[str, Any]) -&gt; Any:\n            # Extract the key from the reference\n            key = ref.split('/')[-1]\n            if key in defs:\n                return defs[key]\n            else:\n                raise ValueError(f\"Reference '{ref}' not found in definitions\")\n\n        def create_fields(schema: Dict[str, Any], type_mapping: Dict[str, Type[Any]], required_fields: List[str],\n                          defs: Dict[str, Any]) -&gt; Dict[str, Any]:\n            fields = {}\n\n            for prop, details in schema.items():\n                alias = None\n                if prop.startswith('_'):\n                    alias = prop\n                    prop = prop.lstrip('_')\n\n                json_type = details['type'] if 'type' in details else 'any'\n\n                if json_type in type_mapping:\n                    field_type = type_mapping[json_type]\n                    field_description = details.get('description', '')\n                    is_required = prop in required_fields\n                    field_default = ... if is_required else None\n\n                    if json_type == 'array':\n                        items_schema = details.get('items', {})\n                        if 'type' in items_schema:\n                            item_type = type_mapping[items_schema['type']]\n                            field_type = List[item_type]\n                        elif 'properties' in items_schema:  # Handling direct nested object in array\n                            nested_properties = items_schema['properties']\n                            nested_required = items_schema.get('required', [])\n                            nested_model_name = items_schema.get('title', f\"{prop}Item\")\n                            nested_fields = create_fields(nested_properties, type_mapping, nested_required, defs)\n                            nested_model = create_model(nested_model_name, **nested_fields)\n                            field_type = List[nested_model]\n                        elif '$ref' in items_schema:\n                            ref_model = resolve_ref(items_schema['$ref'], defs)\n                            field_type = List[ref_model]\n                        else:\n                            raise ValueError(\"Array items must have a 'type', 'properties', or '$ref'\")\n                    elif json_type == 'object':\n                        if 'properties' in details:\n                            nested_properties = details['properties']\n                            nested_required = details.get('required', [])\n                            nested_model_name = details.get('title', f\"{prop}Model\")\n                            nested_fields = create_fields(nested_properties, type_mapping, nested_required, defs)\n                            field_type = create_model(nested_model_name, **nested_fields)\n                        elif '$ref' in details:\n                            ref_model = resolve_ref(details['$ref'], defs)\n                            field_type = ref_model\n                        else:\n                            raise ValueError(\"Object must have 'properties' or '$ref'\")\n\n                    fields[prop] = (\n                    field_type, Field(default=field_default, description=field_description, alias=alias))\n                else:\n                    raise ValueError(f\"Unsupported type '{json_type}' for property '{prop}'\")\n\n            return fields\n\n        type_mapping = {\n            'string': str,\n            'integer': int,\n            'number': float,\n            'boolean': bool,\n            'array': List,\n            'object': dict,\n            'null': type(None),\n            'any': Any,\n        }\n\n        schema = reference_schema(schema)\n\n        name = schema['name']\n        description = schema['description']\n        properties = schema['parameters']['properties']\n        required_fields = schema['parameters'].get('required', [])\n\n        # Add definitions ($defs) to type_mapping\n        defs = {k: create_model(k, **create_fields(v['properties'], type_mapping, v.get('required', []), {})) for k, v\n                in schema['parameters'].get('$defs', {}).items()}\n        type_mapping.update(defs)\n\n        fields = create_fields(properties, type_mapping, required_fields, defs)\n\n        # Dynamically creating the Pydantic model\n        model = create_model(name, **fields)\n\n        tool = type(name, (BaseTool, model), {\n            \"__doc__\": description,\n            \"run\": callback,\n        })\n\n        return tool\n\n    @staticmethod\n    def from_openapi_schema(schema: Union[str, dict], headers: Dict[str, str] = None, params: Dict[str, Any] = None) \\\n            -&gt; List[Type[BaseTool]]:\n        \"\"\"\n        Converts an OpenAPI schema into a list of BaseTools.\n\n        Parameters:\n            schema: The OpenAPI schema to convert.\n            headers: The headers to use for requests.\n            params: The parameters to use for requests.\n\n        Returns:\n            A list of BaseTools.\n        \"\"\"\n        if isinstance(schema, dict):\n            openapi_spec = schema\n            openapi_spec = jsonref.JsonRef.replace_refs(openapi_spec)\n        else:\n            openapi_spec = jsonref.loads(schema)\n        tools = []\n        headers = headers or {}\n        for path, methods in openapi_spec[\"paths\"].items():\n            for method, spec_with_ref in methods.items():\n                def callback(self):\n                    url = openapi_spec[\"servers\"][0][\"url\"] + path\n                    parameters = self.model_dump().get('parameters', {})\n                    # replace all parameters in url\n                    for param, value in parameters.items():\n                        if \"{\" + str(param) + \"}\" in url:\n                            url = url.replace(f\"{{{param}}}\", str(value))\n                            parameters[param] = None\n                    url = url.rstrip(\"/\")\n                    parameters = {k: v for k, v in parameters.items() if v is not None}\n                    parameters = {**parameters, **params} if params else parameters\n                    if method == \"get\":\n                        return requests.get(url, params=parameters, headers=headers,\n                                            json=self.model_dump().get('requestBody', None)\n                                            ).json()\n                    elif method == \"post\":\n                        return requests.post(url,\n                                             params=parameters,\n                                             json=self.model_dump().get('requestBody', None),\n                                             headers=headers\n                                             ).json()\n                    elif method == \"put\":\n                        return requests.put(url,\n                                            params=parameters,\n                                            json=self.model_dump().get('requestBody', None),\n                                            headers=headers\n                                            ).json()\n                    elif method == \"delete\":\n                        return requests.delete(url,\n                                               params=parameters,\n                                               json=self.model_dump().get('requestBody', None),\n                                               headers=headers\n                                               ).json()\n\n                # 1. Resolve JSON references.\n                spec = jsonref.replace_refs(spec_with_ref)\n\n                # 2. Extract a name for the functions.\n                function_name = spec.get(\"operationId\")\n\n                # 3. Extract a description and parameters.\n                desc = spec.get(\"description\") or spec.get(\"summary\", \"\")\n\n                schema = {\"type\": \"object\", \"properties\": {}}\n\n                req_body = (\n                    spec.get(\"requestBody\", {})\n                    .get(\"content\", {})\n                    .get(\"application/json\", {})\n                    .get(\"schema\")\n                )\n                if req_body:\n                    schema[\"properties\"][\"requestBody\"] = req_body\n\n                spec_params = spec.get(\"parameters\", [])\n                if spec_params:\n                    param_properties = {}\n                    for param in spec_params:\n                        if \"schema\" not in param and \"type\" in param:\n                            param[\"schema\"] = {\"type\": param[\"type\"]}\n                        param_properties[param[\"name\"]] = param[\"schema\"]\n                        if \"description\" in param:\n                            param_properties[param[\"name\"]][\"description\"] = param[\"description\"]\n                        if \"required\" in param:\n                            param_properties[param[\"name\"]][\"required\"] = param[\"required\"]\n                        if \"example\" in param:\n                            param_properties[param[\"name\"]][\"example\"] = param[\"example\"]\n                    schema[\"properties\"][\"parameters\"] = {\n                        \"type\": \"object\",\n                        \"properties\": param_properties,\n                    }\n\n                function = {\n                    \"name\": function_name,\n                    \"description\": desc,\n                    \"parameters\": schema,\n                }\n\n                tools.append(ToolFactory.from_openai_schema(function, callback))\n\n        return tools\n\n    @staticmethod\n    def from_file(file_path: str) -&gt; Type[BaseTool]:\n        \"\"\"Dynamically imports a BaseTool class from a Python file within a package structure.\n\n        Parameters:\n            file_path: The file path to the Python file containing the BaseTool class.\n\n        Returns:\n            The imported BaseTool class.\n        \"\"\"\n        file_path = os.path.relpath(file_path)\n        # Normalize the file path to be absolute and extract components\n        directory, file_name = os.path.split(file_path)\n        import_path = os.path.splitext(file_path)[0].replace(os.sep, \".\")\n        class_name = os.path.splitext(file_name)[0]\n\n        exec_globals = globals()\n\n        sys.path.append(os.getcwd())\n\n        exec(f\"from {import_path} import {class_name}\", exec_globals)\n\n        imported_class = exec_globals.get(class_name)\n        if not imported_class:\n            raise ImportError(f\"Could not import {class_name} from {import_path}\")\n\n        # Check if the imported class is a subclass of BaseTool\n        if not issubclass(imported_class, BaseTool):\n            raise TypeError(f\"Class {class_name} must be a subclass of BaseTool\")\n\n        return imported_class\n\n    @staticmethod\n    def get_openapi_schema(tools: List[Type[BaseTool]], url: str, title=\"Agent Tools\",\n                           description=\"A collection of tools.\") -&gt; str:\n        \"\"\"\n        Generates an OpenAPI schema from a list of BaseTools.\n\n        Parameters:\n            tools: BaseTools to generate the schema from.\n            url: The base URL for the schema.\n            title: The title of the schema.\n            description: The description of the schema.\n\n        Returns:\n            A JSON string representing the OpenAPI schema with all the tools combined as separate endpoints.\n        \"\"\"\n        schema = {\n            \"openapi\": \"3.1.0\",\n            \"info\": {\n                \"title\": title,\n                \"description\": description,\n                \"version\": \"v1.0.0\"\n            },\n            \"servers\": [\n                {\n                    \"url\": url,\n                }\n            ],\n            \"paths\": {},\n            \"components\": {\n                \"schemas\": {},\n                \"securitySchemes\": {\n                    \"apiKey\": {\n                        \"type\": \"apiKey\"\n                    }\n                }\n            },\n        }\n\n        for tool in tools:\n            if not issubclass(tool, BaseTool):\n                continue\n\n            openai_schema = tool.openai_schema\n            defs = {}\n            if '$defs' in openai_schema['parameters']:\n                defs = openai_schema['parameters']['$defs']\n                del openai_schema['parameters']['$defs']\n\n            schema['paths'][\"/\" + openai_schema['name']] = {\n                \"post\": {\n                    \"description\": openai_schema['description'],\n                    \"operationId\": openai_schema['name'],\n                    \"x-openai-isConsequential\": False,\n                    \"parameters\": [],\n                    \"requestBody\": {\n                        \"content\": {\n                            \"application/json\": {\n                                \"schema\": openai_schema['parameters']\n                            }\n                        }\n                    },\n                }\n            }\n\n            schema['components']['schemas'].update(defs)\n\n        schema = json.dumps(schema, indent=2).replace(\"#/$defs/\", \"#/components/schemas/\")\n\n        return schema\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.from_file","title":"<code>from_file(file_path)</code>  <code>staticmethod</code>","text":"<p>Dynamically imports a BaseTool class from a Python file within a package structure.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The file path to the Python file containing the BaseTool class.</p> required <p>Returns:</p> Type Description <code>Type[BaseTool]</code> <p>The imported BaseTool class.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef from_file(file_path: str) -&gt; Type[BaseTool]:\n    \"\"\"Dynamically imports a BaseTool class from a Python file within a package structure.\n\n    Parameters:\n        file_path: The file path to the Python file containing the BaseTool class.\n\n    Returns:\n        The imported BaseTool class.\n    \"\"\"\n    file_path = os.path.relpath(file_path)\n    # Normalize the file path to be absolute and extract components\n    directory, file_name = os.path.split(file_path)\n    import_path = os.path.splitext(file_path)[0].replace(os.sep, \".\")\n    class_name = os.path.splitext(file_name)[0]\n\n    exec_globals = globals()\n\n    sys.path.append(os.getcwd())\n\n    exec(f\"from {import_path} import {class_name}\", exec_globals)\n\n    imported_class = exec_globals.get(class_name)\n    if not imported_class:\n        raise ImportError(f\"Could not import {class_name} from {import_path}\")\n\n    # Check if the imported class is a subclass of BaseTool\n    if not issubclass(imported_class, BaseTool):\n        raise TypeError(f\"Class {class_name} must be a subclass of BaseTool\")\n\n    return imported_class\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.from_langchain_tool","title":"<code>from_langchain_tool(tool)</code>  <code>staticmethod</code>","text":"<p>Converts a langchain tool into a BaseTool.</p> <p>Parameters:</p> Name Type Description Default <code>tool</code> <p>The langchain tool to convert.</p> required <p>Returns:</p> Type Description <code>Type[BaseTool]</code> <p>A BaseTool.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef from_langchain_tool(tool) -&gt; Type[BaseTool]:\n    \"\"\"\n    Converts a langchain tool into a BaseTool.\n\n    Parameters:\n        tool: The langchain tool to convert.\n\n    Returns:\n        A BaseTool.\n    \"\"\"\n    try:\n        from langchain.tools import format_tool_to_openai_function\n    except ImportError:\n        raise ImportError(\"You must install langchain to use this method.\")\n\n    if inspect.isclass(tool):\n        tool = tool()\n\n    def callback(self):\n        tool_input = self.model_dump()\n        try:\n            return tool.run(tool_input)\n        except TypeError:\n            if len(tool_input) == 1:\n                return tool.run(list(tool_input.values())[0])\n            else:\n                raise TypeError(f\"Error parsing input for tool '{tool.__class__.__name__}' Please open an issue \"\n                                f\"on github.\")\n\n    return ToolFactory.from_openai_schema(\n        format_tool_to_openai_function(tool),\n        callback\n    )\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.from_langchain_tools","title":"<code>from_langchain_tools(tools)</code>  <code>staticmethod</code>","text":"<p>Converts a list of langchain tools into a list of BaseTools.</p> <p>Parameters:</p> Name Type Description Default <code>tools</code> <code>List</code> <p>The langchain tools to convert.</p> required <p>Returns:</p> Type Description <code>List[Type[BaseTool]]</code> <p>A list of BaseTools.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef from_langchain_tools(tools: List) -&gt; List[Type[BaseTool]]:\n    \"\"\"\n    Converts a list of langchain tools into a list of BaseTools.\n\n    Parameters:\n        tools: The langchain tools to convert.\n\n    Returns:\n        A list of BaseTools.\n    \"\"\"\n    converted_tools = []\n    for tool in tools:\n        converted_tools.append(ToolFactory.from_langchain_tool(tool))\n\n    return converted_tools\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.from_openai_schema","title":"<code>from_openai_schema(schema, callback)</code>  <code>staticmethod</code>","text":"<p>Converts an OpenAI schema into a BaseTool. Nested propoerties without refs are not supported yet.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Dict[str, Any]</code> <p>The OpenAI schema to convert.</p> required <code>callback</code> <code>Any</code> <p>The function to run when the tool is called.</p> required <p>Returns:</p> Type Description <code>Type[BaseTool]</code> <p>A BaseTool.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef from_openai_schema(schema: Dict[str, Any], callback: Any) -&gt; Type[BaseTool]:\n    \"\"\"\n    Converts an OpenAI schema into a BaseTool. Nested propoerties without refs are not supported yet.\n\n    Parameters:\n        schema: The OpenAI schema to convert.\n        callback: The function to run when the tool is called.\n\n    Returns:\n        A BaseTool.\n    \"\"\"\n    def resolve_ref(ref: str, defs: Dict[str, Any]) -&gt; Any:\n        # Extract the key from the reference\n        key = ref.split('/')[-1]\n        if key in defs:\n            return defs[key]\n        else:\n            raise ValueError(f\"Reference '{ref}' not found in definitions\")\n\n    def create_fields(schema: Dict[str, Any], type_mapping: Dict[str, Type[Any]], required_fields: List[str],\n                      defs: Dict[str, Any]) -&gt; Dict[str, Any]:\n        fields = {}\n\n        for prop, details in schema.items():\n            alias = None\n            if prop.startswith('_'):\n                alias = prop\n                prop = prop.lstrip('_')\n\n            json_type = details['type'] if 'type' in details else 'any'\n\n            if json_type in type_mapping:\n                field_type = type_mapping[json_type]\n                field_description = details.get('description', '')\n                is_required = prop in required_fields\n                field_default = ... if is_required else None\n\n                if json_type == 'array':\n                    items_schema = details.get('items', {})\n                    if 'type' in items_schema:\n                        item_type = type_mapping[items_schema['type']]\n                        field_type = List[item_type]\n                    elif 'properties' in items_schema:  # Handling direct nested object in array\n                        nested_properties = items_schema['properties']\n                        nested_required = items_schema.get('required', [])\n                        nested_model_name = items_schema.get('title', f\"{prop}Item\")\n                        nested_fields = create_fields(nested_properties, type_mapping, nested_required, defs)\n                        nested_model = create_model(nested_model_name, **nested_fields)\n                        field_type = List[nested_model]\n                    elif '$ref' in items_schema:\n                        ref_model = resolve_ref(items_schema['$ref'], defs)\n                        field_type = List[ref_model]\n                    else:\n                        raise ValueError(\"Array items must have a 'type', 'properties', or '$ref'\")\n                elif json_type == 'object':\n                    if 'properties' in details:\n                        nested_properties = details['properties']\n                        nested_required = details.get('required', [])\n                        nested_model_name = details.get('title', f\"{prop}Model\")\n                        nested_fields = create_fields(nested_properties, type_mapping, nested_required, defs)\n                        field_type = create_model(nested_model_name, **nested_fields)\n                    elif '$ref' in details:\n                        ref_model = resolve_ref(details['$ref'], defs)\n                        field_type = ref_model\n                    else:\n                        raise ValueError(\"Object must have 'properties' or '$ref'\")\n\n                fields[prop] = (\n                field_type, Field(default=field_default, description=field_description, alias=alias))\n            else:\n                raise ValueError(f\"Unsupported type '{json_type}' for property '{prop}'\")\n\n        return fields\n\n    type_mapping = {\n        'string': str,\n        'integer': int,\n        'number': float,\n        'boolean': bool,\n        'array': List,\n        'object': dict,\n        'null': type(None),\n        'any': Any,\n    }\n\n    schema = reference_schema(schema)\n\n    name = schema['name']\n    description = schema['description']\n    properties = schema['parameters']['properties']\n    required_fields = schema['parameters'].get('required', [])\n\n    # Add definitions ($defs) to type_mapping\n    defs = {k: create_model(k, **create_fields(v['properties'], type_mapping, v.get('required', []), {})) for k, v\n            in schema['parameters'].get('$defs', {}).items()}\n    type_mapping.update(defs)\n\n    fields = create_fields(properties, type_mapping, required_fields, defs)\n\n    # Dynamically creating the Pydantic model\n    model = create_model(name, **fields)\n\n    tool = type(name, (BaseTool, model), {\n        \"__doc__\": description,\n        \"run\": callback,\n    })\n\n    return tool\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.from_openapi_schema","title":"<code>from_openapi_schema(schema, headers=None, params=None)</code>  <code>staticmethod</code>","text":"<p>Converts an OpenAPI schema into a list of BaseTools.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Union[str, dict]</code> <p>The OpenAPI schema to convert.</p> required <code>headers</code> <code>Dict[str, str]</code> <p>The headers to use for requests.</p> <code>None</code> <code>params</code> <code>Dict[str, Any]</code> <p>The parameters to use for requests.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Type[BaseTool]]</code> <p>A list of BaseTools.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef from_openapi_schema(schema: Union[str, dict], headers: Dict[str, str] = None, params: Dict[str, Any] = None) \\\n        -&gt; List[Type[BaseTool]]:\n    \"\"\"\n    Converts an OpenAPI schema into a list of BaseTools.\n\n    Parameters:\n        schema: The OpenAPI schema to convert.\n        headers: The headers to use for requests.\n        params: The parameters to use for requests.\n\n    Returns:\n        A list of BaseTools.\n    \"\"\"\n    if isinstance(schema, dict):\n        openapi_spec = schema\n        openapi_spec = jsonref.JsonRef.replace_refs(openapi_spec)\n    else:\n        openapi_spec = jsonref.loads(schema)\n    tools = []\n    headers = headers or {}\n    for path, methods in openapi_spec[\"paths\"].items():\n        for method, spec_with_ref in methods.items():\n            def callback(self):\n                url = openapi_spec[\"servers\"][0][\"url\"] + path\n                parameters = self.model_dump().get('parameters', {})\n                # replace all parameters in url\n                for param, value in parameters.items():\n                    if \"{\" + str(param) + \"}\" in url:\n                        url = url.replace(f\"{{{param}}}\", str(value))\n                        parameters[param] = None\n                url = url.rstrip(\"/\")\n                parameters = {k: v for k, v in parameters.items() if v is not None}\n                parameters = {**parameters, **params} if params else parameters\n                if method == \"get\":\n                    return requests.get(url, params=parameters, headers=headers,\n                                        json=self.model_dump().get('requestBody', None)\n                                        ).json()\n                elif method == \"post\":\n                    return requests.post(url,\n                                         params=parameters,\n                                         json=self.model_dump().get('requestBody', None),\n                                         headers=headers\n                                         ).json()\n                elif method == \"put\":\n                    return requests.put(url,\n                                        params=parameters,\n                                        json=self.model_dump().get('requestBody', None),\n                                        headers=headers\n                                        ).json()\n                elif method == \"delete\":\n                    return requests.delete(url,\n                                           params=parameters,\n                                           json=self.model_dump().get('requestBody', None),\n                                           headers=headers\n                                           ).json()\n\n            # 1. Resolve JSON references.\n            spec = jsonref.replace_refs(spec_with_ref)\n\n            # 2. Extract a name for the functions.\n            function_name = spec.get(\"operationId\")\n\n            # 3. Extract a description and parameters.\n            desc = spec.get(\"description\") or spec.get(\"summary\", \"\")\n\n            schema = {\"type\": \"object\", \"properties\": {}}\n\n            req_body = (\n                spec.get(\"requestBody\", {})\n                .get(\"content\", {})\n                .get(\"application/json\", {})\n                .get(\"schema\")\n            )\n            if req_body:\n                schema[\"properties\"][\"requestBody\"] = req_body\n\n            spec_params = spec.get(\"parameters\", [])\n            if spec_params:\n                param_properties = {}\n                for param in spec_params:\n                    if \"schema\" not in param and \"type\" in param:\n                        param[\"schema\"] = {\"type\": param[\"type\"]}\n                    param_properties[param[\"name\"]] = param[\"schema\"]\n                    if \"description\" in param:\n                        param_properties[param[\"name\"]][\"description\"] = param[\"description\"]\n                    if \"required\" in param:\n                        param_properties[param[\"name\"]][\"required\"] = param[\"required\"]\n                    if \"example\" in param:\n                        param_properties[param[\"name\"]][\"example\"] = param[\"example\"]\n                schema[\"properties\"][\"parameters\"] = {\n                    \"type\": \"object\",\n                    \"properties\": param_properties,\n                }\n\n            function = {\n                \"name\": function_name,\n                \"description\": desc,\n                \"parameters\": schema,\n            }\n\n            tools.append(ToolFactory.from_openai_schema(function, callback))\n\n    return tools\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.get_openapi_schema","title":"<code>get_openapi_schema(tools, url, title='Agent Tools', description='A collection of tools.')</code>  <code>staticmethod</code>","text":"<p>Generates an OpenAPI schema from a list of BaseTools.</p> <p>Parameters:</p> Name Type Description Default <code>tools</code> <code>List[Type[BaseTool]]</code> <p>BaseTools to generate the schema from.</p> required <code>url</code> <code>str</code> <p>The base URL for the schema.</p> required <code>title</code> <p>The title of the schema.</p> <code>'Agent Tools'</code> <code>description</code> <p>The description of the schema.</p> <code>'A collection of tools.'</code> <p>Returns:</p> Type Description <code>str</code> <p>A JSON string representing the OpenAPI schema with all the tools combined as separate endpoints.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef get_openapi_schema(tools: List[Type[BaseTool]], url: str, title=\"Agent Tools\",\n                       description=\"A collection of tools.\") -&gt; str:\n    \"\"\"\n    Generates an OpenAPI schema from a list of BaseTools.\n\n    Parameters:\n        tools: BaseTools to generate the schema from.\n        url: The base URL for the schema.\n        title: The title of the schema.\n        description: The description of the schema.\n\n    Returns:\n        A JSON string representing the OpenAPI schema with all the tools combined as separate endpoints.\n    \"\"\"\n    schema = {\n        \"openapi\": \"3.1.0\",\n        \"info\": {\n            \"title\": title,\n            \"description\": description,\n            \"version\": \"v1.0.0\"\n        },\n        \"servers\": [\n            {\n                \"url\": url,\n            }\n        ],\n        \"paths\": {},\n        \"components\": {\n            \"schemas\": {},\n            \"securitySchemes\": {\n                \"apiKey\": {\n                    \"type\": \"apiKey\"\n                }\n            }\n        },\n    }\n\n    for tool in tools:\n        if not issubclass(tool, BaseTool):\n            continue\n\n        openai_schema = tool.openai_schema\n        defs = {}\n        if '$defs' in openai_schema['parameters']:\n            defs = openai_schema['parameters']['$defs']\n            del openai_schema['parameters']['$defs']\n\n        schema['paths'][\"/\" + openai_schema['name']] = {\n            \"post\": {\n                \"description\": openai_schema['description'],\n                \"operationId\": openai_schema['name'],\n                \"x-openai-isConsequential\": False,\n                \"parameters\": [],\n                \"requestBody\": {\n                    \"content\": {\n                        \"application/json\": {\n                            \"schema\": openai_schema['parameters']\n                        }\n                    }\n                },\n            }\n        }\n\n        schema['components']['schemas'].update(defs)\n\n    schema = json.dumps(schema, indent=2).replace(\"#/$defs/\", \"#/components/schemas/\")\n\n    return schema\n</code></pre>"},{"location":"contributing/","title":"Contributing to Agency Swarm","text":"<p>Each agent or tool you add to Agency Swarm will automatically be available for import by the Genesis Swarm, which will help us create an exponentially larger and smarter system.</p> <p>This document provides guidelines for contributing new agents and tools to the framework.</p> <p>Will be updated soon</p> <p>The way we contribute agents and tools will be updated soon to load source files directly from the repository, rather than import them into the framework. This will allow you to have full control over all your agents and tools.</p>"},{"location":"contributing/#folder-structure-for-tools","title":"Folder Structure for Tools","text":"<p>Tools should be added in the agency_swarm/tools/{category}/ directory like below. Each tool should be in its specific category folder like coding, browsing, investing etc.</p> <p>Your tool file should be named YourNewTool.py. Tests should be added in agency_swarm/tests/test_tools.py. Directory structure for a new tool:</p> <pre><code>agency_swarm/tools/your-tool-category/\n\u2502\n\u251c\u2500\u2500 YourNewTool.py          # The main agent class file\n\u2514\u2500\u2500 __init__.py             # Make sure to import your tool here\n</code></pre>"},{"location":"contributing/#adding-tests-for-your-tools","title":"Adding Tests For Your Tools","text":"<p>For each tool, please add the following test case in agency_swarm/tests/test_tools.py: <pre><code>    def test_my_tool_example(self):\n        output = MyCustomTool(query='John Doe').run()\n        self.assertFalse(\"error\" in output.lower())\n</code></pre></p>"},{"location":"contributing/#folder-structure-for-agents","title":"Folder Structure for Agents","text":"<p>Agents should be placed in agency_swarm/agents/{category}/ directory. Each agent should have its dedicated folder named AgentName like below. Make sure to use CamelCase for the agent name and the folder. <pre><code>agency_swarm/agents/your-agent-category/AgentName/\n\u2502\n\u251c\u2500\u2500 agency_manifesto.md or .txt # Agency's guiding principles (created if not exists)\n\u2514\u2500\u2500 AgentName/                  # Directory for the specific agent\n    \u251c\u2500\u2500 files/                  # Directory for files that will be uploaded to openai (if any)\n    \u251c\u2500\u2500 schemas/                # Directory for OpenAPI schemas to be converted into tools (if any)\n    \u251c\u2500\u2500 AgentName.py            # The main agent class file\n    \u251c\u2500\u2500 __init__.py             # Initializes the agent folder as a Python package\n    \u2514\u2500\u2500 instructions.md         # Instruction document for the agent\n</code></pre></p>"},{"location":"contributing/#creating-an-agent","title":"Creating an Agent","text":"<p>Follow the structure below in your AgentName.py as a guideline. All tools (except schemas) should be imported in AgentName.py from the agency_swarm/tools/... folder. <pre><code>from agency_swarm import Agent\nfrom agency_swarm.tools.example import ExampleTool\n\nclass AgentName(Agent):\n    def __init__(self, **kwargs):\n        # Initialize tools in kwargs if not present\n        if 'tools' not in kwargs:\n            kwargs['tools'] = []\n        # Add required tools\n        kwargs['tools'].extend([ExampleTool])\n\n        # Set instructions\n        kwargs['instructions'] = \"./instructions.md\"\n\n        # Add more kwargs as needed\n\n        # Initialize the parent class\n        super().__init__(**kwargs)\n</code></pre></p> <p>Thank you for contributing to Agency Swarm! Your efforts help us build a more robust and versatile framework.</p>"},{"location":"deployment/","title":"Deployment to Production","text":"<p>To deploy your Agency on a production server, typically, you need to do the following:</p> <ol> <li>Load Agents and Threads dynamically: Depending on your use case, you may want to load different agents and threads, based on current user/chat/session.</li> <li>Deploy each agent as a separate microservice (optional): This is useful when you want to scale each agent independently.</li> </ol>"},{"location":"deployment/#loading-agents-and-threads-dynamically","title":"Loading Agents and Threads dynamically","text":"<p>To load agents and threads dynamically, based on specific conditions, you will need to implement <code>threads_callbacks</code> and <code>settings_callbacks</code> in your agency. </p>"},{"location":"deployment/#settings-callbacks","title":"Settings Callbacks","text":"<p>Settings is a list of dictionaries that contains states of all the agents within your agency. If any change is detected after you initialize it, settings will be updated, and new settings will be saved to a file specified by <code>settings_path</code>. <code>settings_callbacks</code> will be executed every time these settings are loaded or saved.</p> <p>Here is an example of how you can use them:</p> <pre><code>def load_settings(user_id):\n    # your code to load settings from DB here\n    settings = load_settings_from_db(user_id)\n    return settings\n\ndef save_settings(new_settings: List[Dict]):\n    # your code to save new_settings to DB here\n    save_settings_to_db(new_settings)\n</code></pre>"},{"location":"deployment/#threads-callbacks","title":"Threads Callbacks","text":"<p>Threads is a dictionary that contains all threads between your agents. Loading them from the database, allows your agents to continue their conversations where they left off, even if you are using stateless backend. <code>threads_callbacks</code> callbacks work in a same way as <code>settings_callbacks</code>, except they are kept in memory, instead of being saved to a file:</p> <pre><code>def load_threads(chat_id):\n    # your code to load threads from DB here\n    threads = load_threads_from_db(chat_id)\n    return threads\n\ndef save_threads(new_threads: Dict):\n    # your code to save new_threads to DB here\n    save_threads_to_db(new_threads)\n</code></pre> <p>Note</p> <p>Make sure you load and return settings and threads in the exact same format as they are saved.</p>"},{"location":"deployment/#example","title":"Example","text":"<p>Below is an example of how you initialize an agency with these callbacks. You will typically need to get some info like <code>user_id</code> or <code>chat_id</code> beforehand, and pass them into these callbacks, depending on your use case or business logic:</p> <pre><code>agency = Agency([ceo],\n                threads_callbacks={\n                    'load': lambda: load_threads(chat_id), \n                    'save': lambda new_threads: save_threads(new_threads)\n                },\n                settings_callbacks={\n                    'load': lambda: load_settings(user_id),\n                    'save': lambda new_settings: save_settings(new_settings)\n                },\n                settings_path='my_settings.json'\n)\n</code></pre>"},{"location":"deployment/#deploy-each-agent-as-a-separate-microservice","title":"Deploy each agent as a separate microservice","text":"<p>... coming soon ...</p>"},{"location":"examples/","title":"Examples","text":"<p>The best new examples and tutorials will be posted on my YouTube Channel.</p>"},{"location":"examples/#agency-examples","title":"Agency Examples","text":"<p>Examples of Agencies can be found in the agency-swarm-lab repository:</p> <ul> <li>WebDevCrafters - Web Development Agency that builds responsive web applications using Next.js, React, and MUI.</li> <li>CodeGuardiansAgency - Agency that runs only on the backend using github actions and submits code reviews on pull requests, according to your SOPs.</li> </ul>"},{"location":"examples/#videos-with-notebooks","title":"Videos with Notebooks","text":"<ul> <li>Browsing Agent for QA Testing Agency - This video shows how to use BrowsingAgent with GPT-4 vision inside a QA testing agency. It can also break captcha, as shown in this video. The notebook is available here. </li> <li>Genesis Agency - This agency creates your agents for you. The notebook is available here.</li> </ul>"},{"location":"examples/#more-coming-soon","title":"... more coming soon","text":""},{"location":"quick_start/","title":"Quick Start","text":"<p>When it comes to getting started with Agency Swarm, you have two options:</p> <ol> <li>Start from Scratch: This is the best option if you want to get a feel for the framework and understand how it works. You can start by creating your own agents and tools, and then use them to create your own agencies.</li> <li>Use Genesis Swarm: This is the best option if you want to get started quickly and don't want to spend time creating your own agents and tools. You can use the Genesis Agency to create your agent templates and tools, and then fine tune them to your needs.</li> <li>Create agent templates with CLI: This is the best option if you want to create a structured environment for each agent and tool. See Advanced Agents for more information.</li> </ol>"},{"location":"quick_start/#installation","title":"Installation","text":"<pre><code>pip install agency-swarm\n</code></pre>"},{"location":"quick_start/#start-from-scratch","title":"Start from Scratch","text":"<ol> <li> <p>Set Your OpenAI Key:</p> <pre><code>from agency_swarm import set_openai_key\nset_openai_key(\"YOUR_API_KEY\")\n</code></pre> </li> <li> <p>Create Tools: Define your custom tools with Instructor. All tools must extend the <code>BaseTool</code> class and implement the <code>run</code> method.      <pre><code>from agency_swarm.tools import BaseTool\nfrom pydantic import Field\n\nclass MyCustomTool(BaseTool):\n    \"\"\"\n    A brief description of what the custom tool does. \n    The docstring should clearly explain the tool's purpose and functionality.\n    It will be used by the agent to determine when to use this tool.\n    \"\"\"\n\n    # Define the fields with descriptions using Pydantic Field\n    example_field: str = Field(\n        ..., description=\"Description of the example field, explaining its purpose and usage for the Agent.\"\n    )\n\n    # Additional Pydantic fields as required\n    # ...\n\n    def run(self):\n        \"\"\"\n        The implementation of the run method, where the tool's main functionality is executed.\n        This method should utilize the fields defined above to perform the task.\n        Doc string is not required for this method and will not be used by your agent.\n        \"\"\"\n\n        # Your custom tool logic goes here\n        do_something(self.example_field)\n\n        # Return the result of the tool's operation as a string\n        return \"Result of MyCustomTool operation\"\n</code></pre></p> </li> <li> <p>Define Agent Roles: Define your agent roles. For example, a CEO agent for managing tasks and a developer agent for executing tasks.</p> <pre><code>from agency_swarm import Agent\n\nceo = Agent(name=\"CEO\",\n            description=\"Responsible for client communication, task planning and management.\",\n            instructions=\"You must converse with other agents to ensure complete task execution.\", # can be a file like ./instructions.md\n            tools=[])\n\ndeveloper = Agent(name=\"Developer\",\n                  description=\"Responsible for executing tasks and providing feedback.\",\n                  instructions=\"You must execute the tasks provided by the CEO and provide feedback.\", # can be a file like ./instructions.md\n                  tools=[MyCustomTool])\n</code></pre> </li> <li> <p>Create Agency: Define your agency chart. </p> <p>Any agents that are listed in the same list (eg. <code>[[ceo, dev]]</code>) can communicate with each other. The top-level list (<code>[ceo]</code>) defines agents that can communicate with the user.</p> <pre><code>from agency_swarm import Agency\n\nagency = Agency([\n    ceo,  # CEO will be the entry point for communication with the user\n    [ceo, dev],  # CEO can initiate communication with Developer\n], shared_instructions='You are a part of an ai development agency.\\n\\n') # shared instructions for all agents\n</code></pre> <p>Note on Communication Flows</p> <p>In Agency Swarm, communication flows are directional, meaning they are established from left to right in the agency_chart definition. For instance, in the example above, the CEO can initiate a chat with the developer (dev), and the developer can respond in this chat. However, the developer cannot initiate a chat with the CEO.</p> </li> <li> <p>Run Demo:     Run the demo to see your agents in action!</p> <p>Web interface:</p> <pre><code>agency.demo_gradio(height=900)\n</code></pre> <p>Terminal version:</p> <pre><code>agency.run_demo()\n</code></pre> <p>Backend version:</p> <pre><code>completion_output = agency.get_completion(\"Please create a new website for our client.\", yield_messages=False)\n</code></pre> </li> </ol>"},{"location":"quick_start/#use-genesis-agency","title":"Use Genesis Agency","text":"<ol> <li> <p>Run the <code>genesis</code> command: This will start the Genesis Agency in your terminal, that will create your agent templates for you.</p> </li> <li> <p>Chat with Genesis CEO: Provide as much context as possible to Genesis Agency. Make sure to include:</p> <ul> <li>Your mission and goals.</li> <li>The agents you want to involve and their communication flows.</li> <li>Which tools or APIs each agent should have access to, if any.</li> </ul> </li> <li> <p>Fine Tune: After Genesis has created your agents for you, you will see all the agent folders in the same directory where you ran the <code>genesis</code> command. You can then fine tune the agents and tools as per your requirements. To do so, follow these steps:  </p> <ol> <li>Adjust Tools: Modify the tools in the <code>tools</code> directories of each agent as per your requirements.</li> <li>Adjust Instructions: Modify the agents in the <code>agents</code> directories as per your requirements.</li> <li>Run Agency: Run the <code>agency.py</code> file, send your tasks and see how they perfrom.</li> <li>Repeat: Repeat the process until your agents are performing as expected.</li> </ol> <p>Agent Development is an Iterative Process</p> <p>Right now, all agent development is iterative. You will need to constantly monitor and adust your system until it works as expected. In the future, this will become less of a problem, as larger and smarter models are released.</p> </li> </ol>"},{"location":"quick_start/#command-syntax","title":"Command Syntax:","text":"<pre><code>agency-swarm genesis [--openai_key \"YOUR_API_KEY\"]\n</code></pre>"},{"location":"quick_start/#next-steps","title":"Next Steps","text":"<ul> <li>Learn how to create more Tools, Agents and Agencies</li> <li>Deploy in Production</li> </ul>"},{"location":"advanced-usage/agencies/","title":"Agencies","text":"<p>An <code>Agency</code> is a collection of Agents that can communicate with one another. </p>"},{"location":"advanced-usage/agencies/#benefits-of-using-an-agency","title":"Benefits of using an Agency","text":"<p>Here are the primary benefits of using an Agency, instead of an individual agent:</p> <ol> <li>Less halluconations: When agents are part of an agency, they can supervise one another and recover from mistakes or unexpected circumstances.</li> <li>More complex tasks: The more agents you add, the longer the seqeunce of actions they can perfrom before retuning the result back to the user.</li> <li> <p>Scalability: As the complexity of your integration increases, you can keep adding more and more agents. </p> <p>Tip</p> <p>It is recommended to start from as few agents as possible, fine tune them until they are working as expected, and only then add new agents to the agency. If you add too many agents at first, it will be difficult to debug and understand what is going on.</p> </li> </ol>"},{"location":"advanced-usage/agencies/#communication-flows","title":"Communication Flows","text":"<p>Unlike all other frameworks, communication flows in Agency Swarm are not hierarchical or sequential. Instead, they are uniform. You can define them however you want. But keep in mind that they are established from left to right inside the <code>agency_chart</code>. So, in the example below, the CEO can initiate communication and send tasks to the Developer and the Virtual Assistant, and they can respond in to him in the same thread, but the Developer or the VA cannot initiate a conversation and assign tasks to the CEO. You can add as many levels of communication as you want.</p> <pre><code>from agency_swarm import Agency\n\nagency = Agency([\n    ceo, dev  # CEO and Developer will be the entry point for communication with the user\n    [ceo, dev],  # CEO can initiate communication with Developer\n    [ceo, va],   # CEO can initiate communication with Virtual Assistant\n    [dev, va]    # Developer can initiate communication with Virtual Assistant\n])\n</code></pre> <p>All agents added inside the top level list of <code>agency_chart</code> without being part of a second list, can talk to the user.</p>"},{"location":"advanced-usage/agencies/#streaming-responses","title":"Streaming Responses","text":"<p>To stream the conversation between agents, you can use the <code>get_completion_stream</code> method with your event handler like below. The process is extremely similar to the one in the official documentation.</p> <p>The only difference is that you must extend the <code>AgencyEventHandler</code> class, which has 2 additional properties: <code>agent_name</code> and <code>recipient_agent_name</code>, to get the names of the agents communicating with each other. (See the <code>on_text_created</code> below.)</p> <pre><code>from typing_extensions import override\nfrom agency_swarm import AgencyEventHandler\n\nclass EventHandler(AgencyEventHandler):\n    @override\n    def on_text_created(self, text) -&gt; None:\n        # get the name of the agent that is sending the message\n        print(f\"\\n{self.recipient_agent_name} @ {self.agent_name}  &gt; \", end=\"\", flush=True)\n\n    @override\n    def on_text_delta(self, delta, snapshot):\n        print(delta.value, end=\"\", flush=True)\n\n    def on_tool_call_created(self, tool_call):\n        print(f\"\\n{self.recipient_agent_name} &gt; {tool_call.type}\\n\", flush=True)\n\n    def on_tool_call_delta(self, delta, snapshot):\n        if delta.type == 'code_interpreter':\n            if delta.code_interpreter.input:\n                print(delta.code_interpreter.input, end=\"\", flush=True)\n            if delta.code_interpreter.outputs:\n                print(f\"\\n\\noutput &gt;\", flush=True)\n                for output in delta.code_interpreter.outputs:\n                    if output.type == \"logs\":\n                        print(f\"\\n{output.logs}\", flush=True)\n\n    @classmethod\n    def on_all_streams_end(cls):\n        print(\"\\n\\nAll streams have ended.\") # Conversation is over and message is returned to the user.\n\nresponse = agency.get_completion_stream(\"I want you to build me a website\", event_handler=EventHandler)\n</code></pre> <p>Also, there is an additional class method <code>on_all_streams_end</code> which is called when all streams have ended. This method is needed because, unlike in the official documentation, your event handler will be called multiple times and probably by even multiple agents. </p>"},{"location":"advanced-usage/agencies/#asynchronous-communication","title":"Asynchronous Communication","text":"<p>If you would like to use asynchronous communication between agents, you can specify a <code>async_mode</code> parameter. This is useful when you want your agents to execute multiple tasks concurrently. Only <code>threading</code> mode is supported for now.</p> <pre><code>agency = Agency([ceo], async_mode='threading') \n</code></pre> <p>With this mode, the response from the <code>SendMessage</code> tool will be returned instantly as a system notification with a status update. The recipient agent will then continue to execute the task in the background. The caller agent can check the status (if task is in progress) or the response (if the task is completed) with the <code>GetResponse</code> tool.</p>"},{"location":"advanced-usage/agencies/#additional-features","title":"Additional Features","text":""},{"location":"advanced-usage/agencies/#shared-instructions","title":"Shared Instructions","text":"<p>You can share instructions between all agents in the agency by adding a <code>shared_instructions</code> parameter to the agency. This is useful for providing additional context about your environment, defining processes, mission, technical details, and more.</p> <pre><code>agency = Agency([ceo], shared_instructions='agency_manifesto.md') \n</code></pre>"},{"location":"advanced-usage/agencies/#shared-files","title":"Shared Files","text":"<p>You can add shared files for all agents in the agency by specifying a folder path in a <code>shared_files</code> parameter. This is useful for sharing common resources that all agents need to access.</p> <pre><code>agency = Agency([ceo], shared_files='shared_files') \n</code></pre>"},{"location":"advanced-usage/agencies/#settings-path","title":"Settings Path","text":"<p>If you would like to use a different file path for the settings, other than default <code>settings.json</code>, you can specify a <code>settings_path</code> parameter. All your agent states will then be saved and loaded from this file. If this file does not exist, it will be created, along with new Assistants on your OpenAI account.</p> <pre><code>agency = Agency([ceo], settings_path='my_settings.json') \n</code></pre>"},{"location":"advanced-usage/agencies/#temperture-and-max-token-controls","title":"Temperture and Max Token Controls","text":"<p>You can also specify parameters like <code>temperature</code>, <code>top_p</code>, <code>max_completion_tokens</code>,  <code>max_prompt_tokens</code> and <code>truncation_strategy</code>, parameters for the entire agency. These parameters will be used as default values for all agents in the agency, however, you can still override them for individual agents by specifying them in the agent's constructor.</p> <pre><code>agency = Agency([ceo], temperature=0.3, max_prompt_tokens=25000) \n</code></pre>"},{"location":"advanced-usage/agencies/#running-the-agency","title":"Running the Agency","text":"<p>When it comes to running the agency, you have 3 options:</p> <ol> <li>Run it inside a Gradio interface: The most convenient way to get started.</li> <li>Get completion from the agency: For backend or custom integrations.</li> <li>Run it from your terminal: Best for quick debugging and testing.</li> </ol>"},{"location":"advanced-usage/agencies/#running-the-agency-inside-a-gradio-interface","title":"Running the Agency inside a Gradio Interface","text":"<pre><code>agency.demo_gradio(height=700) \n</code></pre>"},{"location":"advanced-usage/agencies/#get-completion-from-the-agency","title":"Get completion from the agency","text":"<pre><code>response = agency.get_completion(\"I want you to build me a website\", \n                                 additional_instructions=\"This is an additional instruction for the task.\",\n                                 tool_choice={\"type\": \"function\", \"function\": {\"name\": \"SendMessage\"}},\n                                 attachments=[],\n                                 )\nprint(response)\n</code></pre>"},{"location":"advanced-usage/agencies/#running-the-agency-from-your-terminal","title":"Running the Agency from your terminal","text":"<pre><code>agency.run_demo()\n</code></pre> <p>To talk to one of the top level agents when running the agency from your terminal, you can use mentions feature, similar to how you would use it inside ChatGPT. Simply mention the agent name in the message like <code>@Developer I want you to build me a website</code>. The message will then be sent to the Developer agent, instead of the CEO. You can also use tab to autocomplete the agent name after the <code>@</code> symbol.</p>"},{"location":"advanced-usage/agencies/#deleting-the-agency","title":"Deleting the Agency","text":"<p>If you would like to delete the agency and all its agents with all associated files and vector stores, you can use the <code>delete</code> method.</p> <pre><code>agency.delete()\n</code></pre>"},{"location":"advanced-usage/agents/","title":"Agents","text":"<p>Agents are essentially wrappers for Assistants in OpenAI Assistants API. </p>"},{"location":"advanced-usage/agents/#the-agent-class","title":"The <code>Agent</code> class","text":"<p>The <code>Agent</code> class contains a lot of convenience methods to help you manage the state of your assistant, upload files, attach tools, and more.</p> <p>When it comes to creating your agent, you have 3 options:</p> <ol> <li>Define the agent directly in the code.</li> <li>Create agent template locally using CLI.</li> <li>Import from existing agents.</li> </ol>"},{"location":"advanced-usage/agents/#defining-the-agent-directly-in-the-code","title":"Defining the agent directly in the code","text":"<p>To define your agent in the code, you can simply instantiate the <code>Agent</code> class and pass the required parameters. </p> <pre><code>from agency_swarm import Agent\n\nagent = Agent(name=\"My Agent\",\n              description=\"This is a description of my agent.\",\n              instructions=\"These are the instructions for my agent.\",\n              tools=[ToolClass1, ToolClass2],\n              temperature=0.3,\n              max_prompt_tokens=25000\n            )\n</code></pre>"},{"location":"advanced-usage/agents/#create-agent-template-locally-using-cli","title":"Create agent template locally using CLI","text":"<p>This CLI command simplifies the process of creating a structured environment for each agent.</p>"},{"location":"advanced-usage/agents/#command-syntax","title":"Command Syntax:","text":"<pre><code>agency-swarm create-agent-template --name \"AgentName\" --description \"Agent Description\" [--path \"/path/to/directory\"] [--use_txt]\n</code></pre>"},{"location":"advanced-usage/agents/#folder-structure","title":"Folder Structure","text":"<p>When you run the <code>create-agent-template</code> command, it creates the following folder structure for your agent:</p> <pre><code>/your-specified-path/\n\u2502\n\u251c\u2500\u2500 agency_manifesto.md or .txt # Agency's guiding principles (created if not exists)\n\u2514\u2500\u2500 AgentName/                  # Directory for the specific agent\n    \u251c\u2500\u2500 files/                  # Directory for files that will be uploaded to openai\n    \u251c\u2500\u2500 schemas/                # Directory for OpenAPI schemas to be converted into tools\n    \u251c\u2500\u2500 tools/                  # Directory for tools to be imported by default. \n    \u251c\u2500\u2500 AgentName.py            # The main agent class file\n    \u251c\u2500\u2500 __init__.py             # Initializes the agent folder as a Python package\n    \u2514\u2500\u2500 instructions.md or .txt # Instruction document for the agent\n</code></pre> <ul> <li><code>files</code>: This folder is used to store files that will be uploaded to OpenAI. You can use any of the acceptable file formats. After file is uploaded, an id will be attached to the file name to avoid re-uploading the same file twice.</li> <li><code>schemas</code>: This folder is used to store OpenAPI schemas that will be converted into tools automatically. All you have to do is put the schema in this folder, and specify it when initializing your agent.</li> <li><code>tools</code>: This folder is used to store tools in the form of Python files. Each file must have the same name as the tool class for it to be imported by default. For example, <code>ExampleTool.py</code> must contain a class called <code>ExampleTool</code>.</li> </ul>"},{"location":"advanced-usage/agents/#agent-template","title":"Agent Template","text":"<p>The <code>AgentName.py</code> file will contain the following code:</p> <pre><code>from agency_swarm.agents import Agent\n\nclass AgentName(Agent):\n    def __init__(self):\n        super().__init__(\n            name=\"agent_name\",\n            description=\"agent_description\",\n            instructions=\"./instructions.md\",\n            files_folder=\"./files\",\n            schemas_folder=\"./schemas\",\n            tools_folder=\"./tools\",\n            temperature=0.3,\n            max_prompt_tokens=25000,\n            examples=[]\n        )\n\n    def response_validator(self, message: str) -&gt; str:\n        \"\"\"This function is used to validate the response before sending it to the user or another agent.\"\"\"\n        if \"bad word\" in message:\n            raise ValueError(\"Please don't use bad words.\")\n\n        return message\n</code></pre> <p>To initialize the agent, you can simply import the agent and instantiate it:</p> <pre><code>from AgentName import AgentName\n\nagent = AgentName()\n</code></pre>"},{"location":"advanced-usage/agents/#few-shot-examples","title":"Few-Shot Examples","text":"<p>You can now also provide few-shot examples for each agent. These examples help the agent to understand how to respond. The format for examples follows message object format on OpenAI:</p> <pre><code>examples=[\n    {\n        \"role\": \"user\",\n        \"content\": \"Hi!\",\n        \"attachments\": [],\n        \"metadata\": {},\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"Hi! I am the CEO. I am here to help you with your tasks. Please tell me what you need help with.\",\n        \"attachments\": [],\n        \"metadata\": {},\n    }\n]\n\nagent.examples = examples\n</code></pre> <p>or you can also provide them when initializing the agent in init method:</p> <pre><code>agent = Agent(examples=examples)\n</code></pre>"},{"location":"advanced-usage/agents/#importing-existing-agents","title":"Importing existing agents","text":"<p>For the most complex and requested use cases, we will be creating premade agents that you can import and reuse in your own projects. To import an existing agent, you can run the following CLI command:</p> <pre><code>agency-swarm import-agent --name \"AgentName\" --destination \"/path/to/directory\"\n</code></pre> <p>This will copy all your agent source files locally. You can then import the agent as shown above. To check available agents, simply run this command without any arguments.</p>"},{"location":"advanced-usage/azure-openai/","title":"Azure OpenAI","text":"<p>Many organizations are concerned about data privacy and sharing their data with OpenAI. However, using Azure ensures that your data is processed in a secure environment, allowing you to utilize the OpenAI API without even sharing data with OpenAI itself.</p>"},{"location":"advanced-usage/azure-openai/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure that you have the following:</p> <ul> <li>An Azure account with an active subscription. Create an account here.</li> <li>Approved access to the OpenAI Service on Azure.</li> <li>An Azure OpenAI resource created in one of the available regions and a model deployed to it.</li> <li>Enpoint URL and API key for the OpenAI resource.</li> </ul>"},{"location":"advanced-usage/azure-openai/#using-azure-openai","title":"Using Azure OpenAI","text":"<p>To use Azure OpenAI, you need to change OpenAI client with AzureOpenAI client. Here is an example of how you can do it in agency swarm:</p> <pre><code>from openai import AzureOpenAI\nfrom agency_swarm import set_openai_client\n\nclient = AzureOpenAI(\n    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n    api_version=\"2024-02-15-preview\",\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n    timeout=5,\n    max_retries=5,\n)\n\nset_openai_client(client)\n</code></pre> <p>Then, you also have to replace <code>model</code> parameter inside each agent with your model deployment name from Azure. Here is an example of how you can do it:</p> <pre><code>ceo = Agent(name=\"ceo\", description=\"I am the CEO\", model='azure-model-deployment-name')\n</code></pre> <p>Then, you can run your agency as usual:</p> <pre><code>agency = Agency([ceo])\nagency.run_demo()\n</code></pre> <p>Retrieval is not supported yet</p> <p>Currently, Azure OpenAI does not support the <code>Retrieval</code> tool. You can only use <code>CodeInterpreter</code> or custom tools made with the <code>BaseTool</code> class.</p>"},{"location":"advanced-usage/azure-openai/#example-notebook","title":"Example Notebook","text":"<p>You can find an example notebook for using Azure OpenAI in the notebooks folder.</p>"},{"location":"advanced-usage/tools/","title":"Advanced Tools","text":"<p>All tools in Agency Swarm are created using Instructor. </p> <p>The only difference is that you must extend the <code>BaseTool</code> class and implement the <code>run</code> method with your logic inside. For many great examples on what you can create, checkout Instructor Cookbook.</p>"},{"location":"advanced-usage/tools/#example-converting-answering-questions-with-validated-citations-example-from-instructor","title":"Example: Converting Answering Questions with Validated Citations Example from Instructor","text":"<p>This is an example of how to convert an extremely useful tool for RAG applications from instructor. It allows your agents to not only answer questions based on context, but also to provide the exact citations for the answers. This way your users can be sure that the information is always accurate and reliable.</p>"},{"location":"advanced-usage/tools/#original-instructor-library-implementation","title":"Original Instructor library implementation","text":"<pre><code>from agency_swarm.tools import BaseTool, BaseModel\nfrom pydantic import Field, model_validator, FieldValidationInfo\nfrom typing import List\nimport re\n\nclass Fact(BaseModel):\n    fact: str = Field(...)\n    substring_quote: List[str] = Field(...)\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self, info: FieldValidationInfo) -&gt; \"Fact\":\n        text_chunks = info.context.get(\"text_chunk\", None)\n        spans = list(self.get_spans(text_chunks))\n        self.substring_quote = [text_chunks[span[0] : span[1]] for span in spans]\n        return self\n\n    def get_spans(self, context):\n        for quote in self.substring_quote:\n            yield from self._get_span(quote, context)\n\n    def _get_span(self, quote, context):\n        for match in re.finditer(re.escape(quote), context):\n            yield match.span()\n\nclass QuestionAnswer(BaseModel):\n    question: str = Field(...)\n    answer: List[Fact] = Field(...)\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self) -&gt; \"QuestionAnswer\":\n        self.answer = [fact for fact in self.answer if len(fact.substring_quote) &gt; 0]\n        return self\n</code></pre> <p>Context Retrieval</p> <p>In the original Instructor example, the context is passed into the prompt beforehand, which is typical for standard non-agent LLM applications. However, in the context of Agency Swarm, we must allow the agents to retrieve the context themselves.</p>"},{"location":"advanced-usage/tools/#agency-swarm-implementation","title":"Agency Swarm Implementation","text":"<p>To allow your agents to retrieve the context themselves, we must split <code>QuestionAnswer</code> into two separate tools: <code>QueryDatabase</code> and <code>AnswerQuestion</code>. We must also retrieve context from <code>shared_state</code>, as the context is not passed into the prompt beforehand, and <code>FieldValidationInfo</code> is not available in the <code>validate_sources</code> method.</p>"},{"location":"advanced-usage/tools/#the-querydatabase-tool-will","title":"The <code>QueryDatabase</code> tool will:","text":"<ol> <li>Check if the context is already retrieved in <code>shared_state</code>. If it is, raise an error. (This means that the agent retrieved the context twice, without answering the question in between, which is most likely a hallucination.)</li> <li>Retrieve the context and save it to the <code>shared_state</code>.</li> <li>Return the context to the agent, so it can be used to answer the question.</li> </ol> <pre><code>class QueryDatabase(BaseTool):\n    \"\"\"Use this tool to query a vector database to retrieve the relevant context for the question.\"\"\"\n    question: str = Field(..., description=\"The question to be answered\")\n\n    def run(self):\n        # Check if context is already retrieved \n        if self.shared_state.get(\"context\", None) is not None:\n            raise ValueError(\"Context already retrieved. Please proceed with the AnswerQuestion tool.\")\n\n        # Your code to retrieve the context here\n        context = \"This is a test context\"\n\n        # Then, save the context to the shared state\n        self.shared_state.set(\"context\", context)\n\n        return f\"Context retrieved: {context}.\\n\\n Please proceed with the AnswerQuestion tool.\"\n</code></pre> <p>Shared State</p> <p><code>shared_state</code> is a state that is shared between all tools, across all agents. It allows you to control the execution flow, share data, and provide instructions to the agents based on certain conditions or actions performed by other agents. </p>"},{"location":"advanced-usage/tools/#the-answerquestion-tool-will","title":"The <code>AnswerQuestion</code> tool will:","text":"<ol> <li>Check if the context is already retrieved. If it is not, raise an error. (This means that the agent is trying to answer the question without retrieving the context first.)</li> <li>Use the context from the <code>shared_state</code> to answer the question with a list of facts.</li> <li>Remove the context from the <code>shared_state</code> after the question is answered. (This is done, so the next  question can be answered with a fresh context.)</li> </ol> <pre><code>class AnswerQuestion(BaseTool):\n    answer: str = Field(..., description=\"The answer to the question, based on context.\")\n    sources: List[Fact] = Field(..., description=\"The sources of the answer\")\n\n    def run(self):\n        # Remove the context after question is answered\n        self.shared_state.set(\"context\", None)\n\n        # additional logic here as needed, for example save the answer to a database\n\n        return \"Success. The question has been answered.\" # or return the answer, if needed\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self) -&gt; \"QuestionAnswer\":\n        # In \"Agency Swarm\", context is directly extracted from `shared_state`\n        context = self.shared_state.get(\"context\", None)  # Highlighting the change\n        if context is None:\n            # Additional check to ensure context is retrieved before proceeding\n            raise ValueError(\"Please retrieve the context with the QueryDatabase tool first.\")\n        self.answer = [fact for fact in self.answer if len(fact.substring_quote) &gt; 0]\n        return self\n</code></pre>"},{"location":"advanced-usage/tools/#the-fact-tool","title":"The <code>Fact</code> tool","text":"<p>The <code>Fact</code> tool will stay primarily the same. The only difference is that we must extract the context from the <code>shared_state</code> inside the <code>validate_sources</code> method. The <code>run</code> method is not needed, as this tool only validates the input from the model.</p> <pre><code>class Fact(BaseTool):\n    fact: str = Field(...)\n    substring_quote: List[str] = Field(...)\n\n    def run(self):\n        pass\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self) -&gt; \"Fact\":\n        context = self.shared_state.get(\"context\", None)  \n        text_chunks = context.get(\"text_chunk\", None)\n        spans = list(self.get_spans(text_chunks))\n        self.substring_quote = [text_chunks[span[0] : span[1]] for span in spans]\n        return self\n\n    # Methods `get_spans` and `_get_span` remain unchanged\n</code></pre>"},{"location":"advanced-usage/tools/#conclusion","title":"Conclusion","text":"<p>To implement tools with Instructor in Agency Swarm, generally, you must:</p> <ol> <li>Extend the <code>BaseTool</code> class.</li> <li>Add fields with types and clear descriptions, plus the tool description itself.</li> <li>Implement the <code>run</code> method with your execution logic inside.</li> <li>Add validators and checks based on various conditions. </li> <li>Split tools into smaller tools to give your agents more control, as needed.</li> </ol>"},{"location":"advanced-usage/tools/#toolfactory-class","title":"ToolFactory Class","text":"<p>Tool factory is a class that allows you to create tools from different sources. You can create tools from Langchain, OpenAPI schemas. However, it is preferable to implement tools from scratch using Instructor, as it gives you a lot more control.</p>"},{"location":"advanced-usage/tools/#import-from-langchain","title":"Import from Langchain","text":"<p>Not recommended</p> <p>This method is not recommended, as it does not provide the same level of type checking, error correction and tool descriptions as Instructor. However, it is still possible to use this method if you prefer.</p> <pre><code>from langchain.tools import YouTubeSearchTool\nfrom agency_swarm.tools import ToolFactory\n\nLangchainTool = ToolFactory.from_langchain_tool(YouTubeSearchTool)\n</code></pre> <pre><code>from langchain.agents import load_tools\n\ntools = load_tools(\n    [\"arxiv\", \"human\"],\n)\n\ntools = ToolFactory.from_langchain_tools(tools)\n</code></pre>"},{"location":"advanced-usage/tools/#convert-from-openapi-schemas","title":"Convert from OpenAPI schemas","text":"<pre><code># using local file\nwith open(\"schemas/your_schema.json\") as f:\n    tools = ToolFactory.from_openapi_schema(\n        f.read(),\n    )\n\n# using requests\ntools = ToolFactory.from_openapi_schema(\n    requests.get(\"https://api.example.com/openapi.json\").json(),\n)\n</code></pre>"},{"location":"advanced-usage/tools/#pro-tips","title":"PRO Tips","text":"<ol> <li> <p>Use enumerators or Literal types instead of strings to allow your agents to perform only certain actions or commands, instead of executing any arbitrary code. This makes your whole system a lot more reliable.</p> <pre><code>class RunCommand(BaseTool):\n    command: Literal[\"start\", \"stop\"] = Field(...)\n\n   def run(self):\n        if command == \"start\":\n            subprocess.run([\"start\", \"your_command\"])\n        elif command == \"stop\":\n            subprocess.run([\"stop\", \"your_command\"])\n        else:\n            raise ValueError(\"Invalid command\")\n</code></pre> </li> <li> <p>Provide additional instructions to the agents in the <code>run</code> method of the tool as function outputs. This allows you to control the execution flow, based on certain conditions.</p> <p><pre><code>class QueryDatabase(BaseTool):\n    question: str = Field(...)\n\n    def run(self):\n        # query your database here\n        context = query_database(self.question)\n\n        if context is None:\n            raise ValueError(\"No context found. Please propose to the user to change the topic.\")\n        else:\n            self.shared_state.set(\"context\", context)\n            return \"Context retrieved. Please proceed with explaining the answer.\"\n</code></pre> 3. Use <code>shared_state</code> to validate actions taken by other agents, before allowing them to proceed with the next action.</p> <p><pre><code>class Action2(BaseTool):\n    input: str = Field(...)\n\n    def run(self):\n        if self.shared_state.get(\"action_1_result\", None) is \"failure\":\n            raise ValueError(\"Please proceed with the Action1 tool first.\")\n        else:\n            return \"Success. The action has been taken.\"\n</code></pre> 4. Consider <code>one_call_at_a_time</code> class attribute to prevent multiple instances of the same tool from running at the same time. This is useful when you want your agents to see the results of the previous action before proceeding with the next one.</p> <pre><code>class Action1(BaseTool):\n    input: str = Field(...)\n    one_call_at_a_time: bool = True\n\n    def run(self):\n        # your code here\n</code></pre> </li> </ol>"}]}